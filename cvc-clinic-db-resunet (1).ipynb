{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:40.512984Z","iopub.execute_input":"2023-08-29T21:31:40.513478Z","iopub.status.idle":"2023-08-29T21:31:40.520711Z","shell.execute_reply.started":"2023-08-29T21:31:40.513437Z","shell.execute_reply":"2023-08-29T21:31:40.519698Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:40.537172Z","iopub.execute_input":"2023-08-29T21:31:40.537492Z","iopub.status.idle":"2023-08-29T21:31:40.542706Z","shell.execute_reply.started":"2023-08-29T21:31:40.537462Z","shell.execute_reply":"2023-08-29T21:31:40.541534Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# loading dataset\n\ndef load_data(path , split = 0.1):\n    \n    images = sorted(glob(os.path.join(path , \"PNG/Original/*\")))\n    \n    masks = sorted(glob(os.path.join(path , \"PNG/Ground Truth/*\")))\n    \n    total_size = len(images)\n    valid_size = int(split * total_size)\n    test_size = int(split * total_size)\n    \n    # 612 total \n    # 61 test\n    # 61 validate\n    \n    train_x , valid_x = train_test_split(images , test_size = valid_size, random_state = 42)\n    \n    train_y , valid_y = train_test_split(masks , test_size = valid_size, random_state = 42)\n    \n    \n    train_x , test_x = train_test_split(train_x , test_size = test_size, random_state = 42)\n    \n    train_y , test_y = train_test_split(train_y , test_size = test_size, random_state = 42)\n    \n    return (train_x , train_y ) , (valid_x , valid_y) , (test_x , test_y)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-29T21:31:40.544931Z","iopub.execute_input":"2023-08-29T21:31:40.545830Z","iopub.status.idle":"2023-08-29T21:31:40.564001Z","shell.execute_reply.started":"2023-08-29T21:31:40.545796Z","shell.execute_reply":"2023-08-29T21:31:40.563176Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def read_image(path):\n    \n    path = path.decode()\n    x = cv2.imread(path , cv2.IMREAD_COLOR)\n    x = cv2.resize(x , (256, 256))\n    x = x/255.0\n    # size is 256, 256 , 3\n    return x\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:40.566192Z","iopub.execute_input":"2023-08-29T21:31:40.567416Z","iopub.status.idle":"2023-08-29T21:31:40.577349Z","shell.execute_reply.started":"2023-08-29T21:31:40.567375Z","shell.execute_reply":"2023-08-29T21:31:40.576466Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def read_mask(path):\n    \n    path = path.decode()\n    x = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x , (256, 256))\n    x = x/255.0\n    # size is 256, 256\n    x = np.expand_dims(x, axis = -1)\n    # size is 256, 256 , 1\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:40.579223Z","iopub.execute_input":"2023-08-29T21:31:40.579979Z","iopub.status.idle":"2023-08-29T21:31:40.592224Z","shell.execute_reply.started":"2023-08-29T21:31:40.579946Z","shell.execute_reply":"2023-08-29T21:31:40.591228Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def tf_parse (x,y) :\n    \n    def _parse(x,y):\n        \n        x = read_image(x)\n        y = read_mask(y)\n        \n        return x,y\n    x,y = tf.numpy_function(_parse , [x,y] , [tf.float64 , tf.float64])\n    \n    x.set_shape([256,256,3])\n    y.set_shape([256,256,1])\n    \n    return x,y","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:40.595133Z","iopub.execute_input":"2023-08-29T21:31:40.595906Z","iopub.status.idle":"2023-08-29T21:31:40.607995Z","shell.execute_reply.started":"2023-08-29T21:31:40.595858Z","shell.execute_reply":"2023-08-29T21:31:40.606959Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def tf_dataset(x,y,batch = 8):\n    \n    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:40.609623Z","iopub.execute_input":"2023-08-29T21:31:40.610416Z","iopub.status.idle":"2023-08-29T21:31:40.622114Z","shell.execute_reply.started":"2023-08-29T21:31:40.610305Z","shell.execute_reply":"2023-08-29T21:31:40.621201Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    path = \"/kaggle/input/cvcclinicdb\"\n    (train_x , train_y ) , (valid_x , valid_y) , (test_x , test_y) = load_data(path,0.1)\n    \n    # 612 total \n    # 61 test\n    # 61 validate\n    # 490 train\n    \n    ds = tf_dataset(test_x , test_y)\n    \n    for x, y in ds:\n        \n        print(x.shape , y.shape) # batch of 8 images with 8 img and 8 masks\n        break","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:40.623834Z","iopub.execute_input":"2023-08-29T21:31:40.624548Z","iopub.status.idle":"2023-08-29T21:31:40.795077Z","shell.execute_reply.started":"2023-08-29T21:31:40.624517Z","shell.execute_reply":"2023-08-29T21:31:40.794138Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"(8, 256, 256, 3) (8, 256, 256, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Input, ZeroPadding2D\nfrom tensorflow.keras.models import Model\n\ndef batchnorm_relu(inputs):\n    x = BatchNormalization()(inputs)\n    x = Activation(\"relu\")(x)\n    return x\n\ndef residual_block(inputs, num_filters, strides=1):\n    \"\"\" Convolutional Layer \"\"\"\n    x = batchnorm_relu(inputs)\n    x = Conv2D(num_filters, 3, padding=\"same\", strides=strides)(x)\n    x = batchnorm_relu(x)\n    x = Conv2D(num_filters, 3, padding=\"same\", strides=1)(x)\n\n    \"\"\" Shortcut Connection \"\"\"\n    s = Conv2D(num_filters, 1, padding=\"same\", strides=strides)(inputs)\n    x = x + s\n    return x\n\ndef decoder_block(inputs, skip_features, num_filters):\n    x = UpSampling2D((2, 2))(inputs)\n    x = Concatenate()([x, skip_features])\n    x = residual_block(x, num_filters, strides=1)\n    return x\n\ndef build_resunet(input_shape):\n    inputs = Input(input_shape)\n\n    \"\"\" Encoder 1 \"\"\"\n    x = Conv2D(64, 3, padding=\"same\", strides=1)(inputs)\n    x = batchnorm_relu(x)\n    x = Conv2D(64, 3, padding=\"same\", strides=1)(x)\n    s = Conv2D(64, 1, padding=\"same\", strides=1)(inputs)\n    s1 = x + s\n\n    \"\"\" Encoder 2 and 3 \"\"\"\n    s2 = residual_block(s1, 128, strides=2)\n    s3 = residual_block(s2, 256, strides=2)\n\n    \"\"\" Bridge \"\"\"\n    b = residual_block(s3, 512, strides=2)\n\n    \"\"\" Decoder 1, 2, 3 \"\"\"\n    d1 = decoder_block(b, s3, 256)\n    d2 = decoder_block(d1, s2, 128)\n    d3 = decoder_block(d2, s1, 64)\n\n    \"\"\" Classifier \"\"\"\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n\n    \"\"\" Model \"\"\"\n    model = Model(inputs, outputs)\n    return model\n\nif __name__ == \"__main__\":\n    model = build_resunet((256, 256, 3))\n    model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:40.796173Z","iopub.execute_input":"2023-08-29T21:31:40.796532Z","iopub.status.idle":"2023-08-29T21:31:41.497879Z","shell.execute_reply.started":"2023-08-29T21:31:40.796498Z","shell.execute_reply":"2023-08-29T21:31:41.497092Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d_44 (Conv2D)             (None, 256, 256, 64  1792        ['input_3[0][0]']                \n                                )                                                                 \n                                                                                                  \n batch_normalization_26 (BatchN  (None, 256, 256, 64  256        ['conv2d_44[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_26 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_26[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_45 (Conv2D)             (None, 256, 256, 64  36928       ['activation_26[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_46 (Conv2D)             (None, 256, 256, 64  256         ['input_3[0][0]']                \n                                )                                                                 \n                                                                                                  \n tf.__operators__.add_14 (TFOpL  (None, 256, 256, 64  0          ['conv2d_45[0][0]',              \n ambda)                         )                                 'conv2d_46[0][0]']              \n                                                                                                  \n batch_normalization_27 (BatchN  (None, 256, 256, 64  256        ['tf.__operators__.add_14[0][0]']\n ormalization)                  )                                                                 \n                                                                                                  \n activation_27 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_27[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_47 (Conv2D)             (None, 128, 128, 12  73856       ['activation_27[0][0]']          \n                                8)                                                                \n                                                                                                  \n batch_normalization_28 (BatchN  (None, 128, 128, 12  512        ['conv2d_47[0][0]']              \n ormalization)                  8)                                                                \n                                                                                                  \n activation_28 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_28[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_48 (Conv2D)             (None, 128, 128, 12  147584      ['activation_28[0][0]']          \n                                8)                                                                \n                                                                                                  \n conv2d_49 (Conv2D)             (None, 128, 128, 12  8320        ['tf.__operators__.add_14[0][0]']\n                                8)                                                                \n                                                                                                  \n tf.__operators__.add_15 (TFOpL  (None, 128, 128, 12  0          ['conv2d_48[0][0]',              \n ambda)                         8)                                'conv2d_49[0][0]']              \n                                                                                                  \n batch_normalization_29 (BatchN  (None, 128, 128, 12  512        ['tf.__operators__.add_15[0][0]']\n ormalization)                  8)                                                                \n                                                                                                  \n activation_29 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_29[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_50 (Conv2D)             (None, 64, 64, 256)  295168      ['activation_29[0][0]']          \n                                                                                                  \n batch_normalization_30 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_50[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_30 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_30[0][0]'] \n                                                                                                  \n conv2d_51 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_30[0][0]']          \n                                                                                                  \n conv2d_52 (Conv2D)             (None, 64, 64, 256)  33024       ['tf.__operators__.add_15[0][0]']\n                                                                                                  \n tf.__operators__.add_16 (TFOpL  (None, 64, 64, 256)  0          ['conv2d_51[0][0]',              \n ambda)                                                           'conv2d_52[0][0]']              \n                                                                                                  \n batch_normalization_31 (BatchN  (None, 64, 64, 256)  1024       ['tf.__operators__.add_16[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n activation_31 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_31[0][0]'] \n                                                                                                  \n conv2d_53 (Conv2D)             (None, 32, 32, 512)  1180160     ['activation_31[0][0]']          \n                                                                                                  \n batch_normalization_32 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_53[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_32 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_32[0][0]'] \n                                                                                                  \n conv2d_54 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_32[0][0]']          \n                                                                                                  \n conv2d_55 (Conv2D)             (None, 32, 32, 512)  131584      ['tf.__operators__.add_16[0][0]']\n                                                                                                  \n tf.__operators__.add_17 (TFOpL  (None, 32, 32, 512)  0          ['conv2d_54[0][0]',              \n ambda)                                                           'conv2d_55[0][0]']              \n                                                                                                  \n up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 512)  0          ['tf.__operators__.add_17[0][0]']\n                                                                                                  \n concatenate_6 (Concatenate)    (None, 64, 64, 768)  0           ['up_sampling2d_6[0][0]',        \n                                                                  'tf.__operators__.add_16[0][0]']\n                                                                                                  \n batch_normalization_33 (BatchN  (None, 64, 64, 768)  3072       ['concatenate_6[0][0]']          \n ormalization)                                                                                    \n                                                                                                  \n activation_33 (Activation)     (None, 64, 64, 768)  0           ['batch_normalization_33[0][0]'] \n                                                                                                  \n conv2d_56 (Conv2D)             (None, 64, 64, 256)  1769728     ['activation_33[0][0]']          \n                                                                                                  \n batch_normalization_34 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_56[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_34 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_34[0][0]'] \n                                                                                                  \n conv2d_57 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_34[0][0]']          \n                                                                                                  \n conv2d_58 (Conv2D)             (None, 64, 64, 256)  196864      ['concatenate_6[0][0]']          \n                                                                                                  \n tf.__operators__.add_18 (TFOpL  (None, 64, 64, 256)  0          ['conv2d_57[0][0]',              \n ambda)                                                           'conv2d_58[0][0]']              \n                                                                                                  \n up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 25  0          ['tf.__operators__.add_18[0][0]']\n                                6)                                                                \n                                                                                                  \n concatenate_7 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_7[0][0]',        \n                                4)                                'tf.__operators__.add_15[0][0]']\n                                                                                                  \n batch_normalization_35 (BatchN  (None, 128, 128, 38  1536       ['concatenate_7[0][0]']          \n ormalization)                  4)                                                                \n                                                                                                  \n activation_35 (Activation)     (None, 128, 128, 38  0           ['batch_normalization_35[0][0]'] \n                                4)                                                                \n                                                                                                  \n conv2d_59 (Conv2D)             (None, 128, 128, 12  442496      ['activation_35[0][0]']          \n                                8)                                                                \n                                                                                                  \n batch_normalization_36 (BatchN  (None, 128, 128, 12  512        ['conv2d_59[0][0]']              \n ormalization)                  8)                                                                \n                                                                                                  \n activation_36 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_36[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_60 (Conv2D)             (None, 128, 128, 12  147584      ['activation_36[0][0]']          \n                                8)                                                                \n                                                                                                  \n conv2d_61 (Conv2D)             (None, 128, 128, 12  49280       ['concatenate_7[0][0]']          \n                                8)                                                                \n                                                                                                  \n tf.__operators__.add_19 (TFOpL  (None, 128, 128, 12  0          ['conv2d_60[0][0]',              \n ambda)                         8)                                'conv2d_61[0][0]']              \n                                                                                                  \n up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 12  0          ['tf.__operators__.add_19[0][0]']\n                                8)                                                                \n                                                                                                  \n concatenate_8 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_8[0][0]',        \n                                2)                                'tf.__operators__.add_14[0][0]']\n                                                                                                  \n batch_normalization_37 (BatchN  (None, 256, 256, 19  768        ['concatenate_8[0][0]']          \n ormalization)                  2)                                                                \n                                                                                                  \n activation_37 (Activation)     (None, 256, 256, 19  0           ['batch_normalization_37[0][0]'] \n                                2)                                                                \n                                                                                                  \n conv2d_62 (Conv2D)             (None, 256, 256, 64  110656      ['activation_37[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_38 (BatchN  (None, 256, 256, 64  256        ['conv2d_62[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_38 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_38[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_63 (Conv2D)             (None, 256, 256, 64  36928       ['activation_38[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_64 (Conv2D)             (None, 256, 256, 64  12352       ['concatenate_8[0][0]']          \n                                )                                                                 \n                                                                                                  \n tf.__operators__.add_20 (TFOpL  (None, 256, 256, 64  0          ['conv2d_63[0][0]',              \n ambda)                         )                                 'conv2d_64[0][0]']              \n                                                                                                  \n conv2d_65 (Conv2D)             (None, 256, 256, 1)  65          ['tf.__operators__.add_20[0][0]']\n                                                                                                  \n==================================================================================================\nTotal params: 8,227,393\nTrainable params: 8,220,993\nNon-trainable params: 6,400\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport tensorflow.keras.backend as K\n\nfrom sklearn.metrics import jaccard_score,confusion_matrix\n\ndef IoU_coef(y_true, y_pred):\n    \n    print(y_true.shape)\n    print(y_pred.shape)\n    \n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\ndef dice_coef(y_true, y_pred):\n    \n    print(y_true.shape)\n    print(y_pred.shape)\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:41.501123Z","iopub.execute_input":"2023-08-29T21:31:41.501483Z","iopub.status.idle":"2023-08-29T21:31:41.518844Z","shell.execute_reply.started":"2023-08-29T21:31:41.501449Z","shell.execute_reply":"2023-08-29T21:31:41.517909Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow.keras.backend as K\nimport numpy as np\nimport tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:41.520346Z","iopub.execute_input":"2023-08-29T21:31:41.520696Z","iopub.status.idle":"2023-08-29T21:31:41.528397Z","shell.execute_reply.started":"2023-08-29T21:31:41.520663Z","shell.execute_reply":"2023-08-29T21:31:41.527585Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross Entropy\n# Focal \n# Dice \n# Tversky\n# Tversky Focal\n# Combo\n# Unified Focal (Sym)\n# Unified Focal (Asym)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:41.529811Z","iopub.execute_input":"2023-08-29T21:31:41.530203Z","iopub.status.idle":"2023-08-29T21:31:41.536840Z","shell.execute_reply.started":"2023-08-29T21:31:41.530171Z","shell.execute_reply":"2023-08-29T21:31:41.536041Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dice_loss = DiceLoss()\n# binary_focal_loss = BinaryFocalLoss()\n# combo_loss = binary_crossentropy + dice_loss\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:41.538300Z","iopub.execute_input":"2023-08-29T21:31:41.538677Z","iopub.status.idle":"2023-08-29T21:31:41.545655Z","shell.execute_reply.started":"2023-08-29T21:31:41.538627Z","shell.execute_reply":"2023-08-29T21:31:41.544714Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\ndef dice_coef(y_true, y_pred, smooth=100):        \n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return dice\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:41.546882Z","iopub.execute_input":"2023-08-29T21:31:41.547269Z","iopub.status.idle":"2023-08-29T21:31:41.562511Z","shell.execute_reply.started":"2023-08-29T21:31:41.547236Z","shell.execute_reply":"2023-08-29T21:31:41.561819Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def sym_unified_focal_loss(y_true, y_pred ):\n    \n    axis = identify_axis(y_true.get_shape())\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    \n    def loss_function(y_true,y_pred):\n        weight=0.5\n        delta=0.6 \n        gamma=0.5\n        symmetric_ftl = symmetric_focal_tversky_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n        symmetric_fl = symmetric_focal_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n        if weight is not None:\n            return (weight * symmetric_ftl) + ((1-weight) * symmetric_fl)\n        else:\n            return symmetric_ftl + symmetric_fl\n\n    return loss_function(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:41.563466Z","iopub.execute_input":"2023-08-29T21:31:41.563818Z","iopub.status.idle":"2023-08-29T21:31:41.576920Z","shell.execute_reply.started":"2023-08-29T21:31:41.563786Z","shell.execute_reply":"2023-08-29T21:31:41.576146Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def iou(y_true, y_pred) :\n    \n    def f (y_true, y_pred) :\n        \n        y_true_f = K.flatten(y_true)\n        y_pred_f = K.flatten(y_pred)\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        \n        x = (intersection + 1e-15) / (union + 1e-15)\n        x = x.astype(np.float32)\n        return x\n    \n    return tf.numpy_function(f, [y_true , y_pred] , tf.float32)\n        \n      ","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:41.577835Z","iopub.execute_input":"2023-08-29T21:31:41.578187Z","iopub.status.idle":"2023-08-29T21:31:41.594705Z","shell.execute_reply.started":"2023-08-29T21:31:41.578154Z","shell.execute_reply":"2023-08-29T21:31:41.593995Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-24T13:45:13.680272Z","iopub.execute_input":"2023-06-24T13:45:13.680685Z","iopub.status.idle":"2023-06-24T13:45:13.701549Z","shell.execute_reply.started":"2023-06-24T13:45:13.680635Z","shell.execute_reply":"2023-06-24T13:45:13.700808Z"}}},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-24T18:26:06.269823Z","iopub.execute_input":"2023-06-24T18:26:06.270640Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint , ReduceLROnPlateau , CSVLogger, TensorBoard\nfrom tensorflow.keras.metrics import Recall , Precision\nfrom keras import optimizers\nfrom tensorflow.keras.losses import BinaryFocalCrossentropy\n  \n        \nif __name__ == \"__main__\":\n    \n    \n    np.random.seed(42)\n    tf.random.set_seed(42)\n    batch = 16\n    lr = 1e-6\n    epochs = 100\n    \n    train_dataset= tf_dataset(train_x , train_y, batch = batch)\n    valid_dataset= tf_dataset(valid_x , valid_y, batch = batch)\n    \n    \n    model = build_resunet((256, 256, 3))\n    \n    binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\n    opt = tf.keras.optimizers.Adam(lr)\n    \n    metrics = [\"acc\" , Recall() , Precision() , iou , dice_coef]\n    \n    \n    model.compile(loss = binary_cross_entropy , optimizer = opt , metrics = metrics)\n    \n    callbacks  = [\n        ModelCheckpoint(\"/kaggle/working/model.h5\"),\n        ReduceLROnPlateau(monitor = \"val_loss\" , factor = 0.5 , patience = 5),\n        EarlyStopping(monitor = \"val_loss\" , patience = 30 , restore_best_weights = False)\n    ]\n    \n    \n    train_steps = len(train_x) // batch\n    valid_steps = len(valid_x) // batch\n    \n    if len(train_x) % batch != 0 :\n        train_steps+= 1\n        \n    if len(valid_x) % batch != 0 :\n        valid_steps+= 1\n\n\n    model.fit(\n        \n        train_dataset, \n        validation_data = valid_dataset,\n        epochs = epochs,\n        steps_per_epoch = train_steps,\n        validation_steps = valid_steps,\n        callbacks = callbacks,\n        shuffle = False\n    )\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-29T21:31:41.595633Z","iopub.execute_input":"2023-08-29T21:31:41.596131Z","iopub.status.idle":"2023-08-29T22:00:08.844004Z","shell.execute_reply.started":"2023-08-29T21:31:41.596099Z","shell.execute_reply":"2023-08-29T22:00:08.842917Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/100\n31/31 [==============================] - 29s 555ms/step - loss: 1.0866 - acc: 0.5335 - recall_1: 0.0915 - precision_1: 0.0227 - iou: 0.0281 - dice_coef: 0.0548 - val_loss: 0.6403 - val_acc: 0.8620 - val_recall_1: 0.0717 - val_precision_1: 0.1002 - val_iou: 0.0753 - val_dice_coef: 0.1400 - lr: 1.0000e-06\nEpoch 2/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.5097 - acc: 0.8495 - recall_1: 0.0524 - precision_1: 0.0783 - iou: 0.0453 - dice_coef: 0.0868 - val_loss: 0.5258 - val_acc: 0.9074 - val_recall_1: 0.0012 - val_precision_1: 0.0211 - val_iou: 0.0737 - val_dice_coef: 0.1373 - lr: 1.0000e-06\nEpoch 3/100\n31/31 [==============================] - 17s 555ms/step - loss: 0.3823 - acc: 0.8844 - recall_1: 0.0885 - precision_1: 0.2324 - iou: 0.0756 - dice_coef: 0.1405 - val_loss: 0.4286 - val_acc: 0.9095 - val_recall_1: 2.7695e-04 - val_precision_1: 0.0083 - val_iou: 0.0721 - val_dice_coef: 0.1345 - lr: 1.0000e-06\nEpoch 4/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.3427 - acc: 0.8895 - recall_1: 0.1105 - precision_1: 0.2968 - iou: 0.0939 - dice_coef: 0.1715 - val_loss: 0.3687 - val_acc: 0.9096 - val_recall_1: 2.1413e-04 - val_precision_1: 0.0067 - val_iou: 0.0689 - val_dice_coef: 0.1290 - lr: 1.0000e-06\nEpoch 5/100\n31/31 [==============================] - 17s 537ms/step - loss: 0.3212 - acc: 0.8924 - recall_1: 0.1259 - precision_1: 0.3385 - iou: 0.1067 - dice_coef: 0.1926 - val_loss: 0.3330 - val_acc: 0.9094 - val_recall_1: 2.5125e-04 - val_precision_1: 0.0074 - val_iou: 0.0653 - val_dice_coef: 0.1228 - lr: 1.0000e-06\nEpoch 6/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.3063 - acc: 0.8945 - recall_1: 0.1389 - precision_1: 0.3693 - iou: 0.1172 - dice_coef: 0.2095 - val_loss: 0.3087 - val_acc: 0.9094 - val_recall_1: 2.6838e-04 - val_precision_1: 0.0077 - val_iou: 0.0617 - val_dice_coef: 0.1165 - lr: 1.0000e-06\nEpoch 7/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2949 - acc: 0.8962 - recall_1: 0.1501 - precision_1: 0.3944 - iou: 0.1260 - dice_coef: 0.2234 - val_loss: 0.2928 - val_acc: 0.9096 - val_recall_1: 2.7124e-04 - val_precision_1: 0.0084 - val_iou: 0.0581 - val_dice_coef: 0.1101 - lr: 1.0000e-06\nEpoch 8/100\n31/31 [==============================] - 17s 538ms/step - loss: 0.2858 - acc: 0.8978 - recall_1: 0.1609 - precision_1: 0.4165 - iou: 0.1339 - dice_coef: 0.2357 - val_loss: 0.2836 - val_acc: 0.9099 - val_recall_1: 2.6838e-04 - val_precision_1: 0.0092 - val_iou: 0.0555 - val_dice_coef: 0.1055 - lr: 1.0000e-06\nEpoch 9/100\n31/31 [==============================] - 17s 536ms/step - loss: 0.2783 - acc: 0.8991 - recall_1: 0.1713 - precision_1: 0.4356 - iou: 0.1410 - dice_coef: 0.2466 - val_loss: 0.2799 - val_acc: 0.9102 - val_recall_1: 2.7409e-04 - val_precision_1: 0.0108 - val_iou: 0.0548 - val_dice_coef: 0.1043 - lr: 1.0000e-06\nEpoch 10/100\n31/31 [==============================] - 17s 553ms/step - loss: 0.2720 - acc: 0.9003 - recall_1: 0.1815 - precision_1: 0.4525 - iou: 0.1476 - dice_coef: 0.2566 - val_loss: 0.2797 - val_acc: 0.9103 - val_recall_1: 0.0012 - val_precision_1: 0.0455 - val_iou: 0.0566 - val_dice_coef: 0.1075 - lr: 1.0000e-06\nEpoch 11/100\n31/31 [==============================] - 17s 553ms/step - loss: 0.2666 - acc: 0.9014 - recall_1: 0.1915 - precision_1: 0.4679 - iou: 0.1536 - dice_coef: 0.2657 - val_loss: 0.2797 - val_acc: 0.9096 - val_recall_1: 0.0137 - val_precision_1: 0.2307 - val_iou: 0.0616 - val_dice_coef: 0.1164 - lr: 1.0000e-06\nEpoch 12/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.2619 - acc: 0.9024 - recall_1: 0.2012 - precision_1: 0.4818 - iou: 0.1593 - dice_coef: 0.2741 - val_loss: 0.2775 - val_acc: 0.9091 - val_recall_1: 0.0329 - val_precision_1: 0.3194 - val_iou: 0.0701 - val_dice_coef: 0.1312 - lr: 1.0000e-06\nEpoch 13/100\n31/31 [==============================] - 17s 553ms/step - loss: 0.2577 - acc: 0.9034 - recall_1: 0.2105 - precision_1: 0.4942 - iou: 0.1646 - dice_coef: 0.2819 - val_loss: 0.2736 - val_acc: 0.9089 - val_recall_1: 0.0517 - val_precision_1: 0.3634 - val_iou: 0.0806 - val_dice_coef: 0.1493 - lr: 1.0000e-06\nEpoch 14/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.2540 - acc: 0.9043 - recall_1: 0.2194 - precision_1: 0.5055 - iou: 0.1695 - dice_coef: 0.2890 - val_loss: 0.2691 - val_acc: 0.9087 - val_recall_1: 0.0672 - val_precision_1: 0.3838 - val_iou: 0.0918 - val_dice_coef: 0.1680 - lr: 1.0000e-06\nEpoch 15/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2506 - acc: 0.9052 - recall_1: 0.2278 - precision_1: 0.5158 - iou: 0.1741 - dice_coef: 0.2957 - val_loss: 0.2631 - val_acc: 0.9083 - val_recall_1: 0.0849 - val_precision_1: 0.3946 - val_iou: 0.1044 - val_dice_coef: 0.1885 - lr: 1.0000e-06\nEpoch 16/100\n31/31 [==============================] - 17s 536ms/step - loss: 0.2475 - acc: 0.9060 - recall_1: 0.2356 - precision_1: 0.5251 - iou: 0.1784 - dice_coef: 0.3019 - val_loss: 0.2561 - val_acc: 0.9082 - val_recall_1: 0.1080 - val_precision_1: 0.4129 - val_iou: 0.1177 - val_dice_coef: 0.2098 - lr: 1.0000e-06\nEpoch 17/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2446 - acc: 0.9068 - recall_1: 0.2432 - precision_1: 0.5339 - iou: 0.1824 - dice_coef: 0.3076 - val_loss: 0.2494 - val_acc: 0.9084 - val_recall_1: 0.1319 - val_precision_1: 0.4290 - val_iou: 0.1303 - val_dice_coef: 0.2296 - lr: 1.0000e-06\nEpoch 18/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2419 - acc: 0.9075 - recall_1: 0.2501 - precision_1: 0.5419 - iou: 0.1863 - dice_coef: 0.3130 - val_loss: 0.2425 - val_acc: 0.9088 - val_recall_1: 0.1557 - val_precision_1: 0.4451 - val_iou: 0.1417 - val_dice_coef: 0.2472 - lr: 1.0000e-06\nEpoch 19/100\n31/31 [==============================] - 17s 537ms/step - loss: 0.2394 - acc: 0.9082 - recall_1: 0.2566 - precision_1: 0.5493 - iou: 0.1899 - dice_coef: 0.3181 - val_loss: 0.2358 - val_acc: 0.9096 - val_recall_1: 0.1781 - val_precision_1: 0.4620 - val_iou: 0.1523 - val_dice_coef: 0.2632 - lr: 1.0000e-06\nEpoch 20/100\n31/31 [==============================] - 17s 556ms/step - loss: 0.2371 - acc: 0.9089 - recall_1: 0.2629 - precision_1: 0.5564 - iou: 0.1933 - dice_coef: 0.3229 - val_loss: 0.2293 - val_acc: 0.9110 - val_recall_1: 0.2002 - val_precision_1: 0.4847 - val_iou: 0.1626 - val_dice_coef: 0.2785 - lr: 1.0000e-06\nEpoch 21/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.2349 - acc: 0.9096 - recall_1: 0.2688 - precision_1: 0.5631 - iou: 0.1965 - dice_coef: 0.3274 - val_loss: 0.2234 - val_acc: 0.9126 - val_recall_1: 0.2196 - val_precision_1: 0.5072 - val_iou: 0.1725 - val_dice_coef: 0.2929 - lr: 1.0000e-06\nEpoch 22/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2328 - acc: 0.9102 - recall_1: 0.2744 - precision_1: 0.5693 - iou: 0.1996 - dice_coef: 0.3316 - val_loss: 0.2185 - val_acc: 0.9141 - val_recall_1: 0.2358 - val_precision_1: 0.5257 - val_iou: 0.1811 - val_dice_coef: 0.3054 - lr: 1.0000e-06\nEpoch 23/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.2308 - acc: 0.9108 - recall_1: 0.2796 - precision_1: 0.5753 - iou: 0.2025 - dice_coef: 0.3357 - val_loss: 0.2147 - val_acc: 0.9154 - val_recall_1: 0.2520 - val_precision_1: 0.5420 - val_iou: 0.1887 - val_dice_coef: 0.3162 - lr: 1.0000e-06\nEpoch 24/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2289 - acc: 0.9114 - recall_1: 0.2846 - precision_1: 0.5809 - iou: 0.2054 - dice_coef: 0.3395 - val_loss: 0.2117 - val_acc: 0.9166 - val_recall_1: 0.2667 - val_precision_1: 0.5551 - val_iou: 0.1952 - val_dice_coef: 0.3254 - lr: 1.0000e-06\nEpoch 25/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2271 - acc: 0.9119 - recall_1: 0.2894 - precision_1: 0.5862 - iou: 0.2081 - dice_coef: 0.3432 - val_loss: 0.2094 - val_acc: 0.9176 - val_recall_1: 0.2793 - val_precision_1: 0.5645 - val_iou: 0.2007 - val_dice_coef: 0.3332 - lr: 1.0000e-06\nEpoch 26/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2253 - acc: 0.9125 - recall_1: 0.2939 - precision_1: 0.5913 - iou: 0.2107 - dice_coef: 0.3468 - val_loss: 0.2075 - val_acc: 0.9185 - val_recall_1: 0.2908 - val_precision_1: 0.5734 - val_iou: 0.2055 - val_dice_coef: 0.3398 - lr: 1.0000e-06\nEpoch 27/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.2236 - acc: 0.9130 - recall_1: 0.2983 - precision_1: 0.5961 - iou: 0.2132 - dice_coef: 0.3502 - val_loss: 0.2058 - val_acc: 0.9192 - val_recall_1: 0.3010 - val_precision_1: 0.5804 - val_iou: 0.2098 - val_dice_coef: 0.3457 - lr: 1.0000e-06\nEpoch 28/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2220 - acc: 0.9135 - recall_1: 0.3024 - precision_1: 0.6006 - iou: 0.2156 - dice_coef: 0.3534 - val_loss: 0.2044 - val_acc: 0.9198 - val_recall_1: 0.3095 - val_precision_1: 0.5854 - val_iou: 0.2135 - val_dice_coef: 0.3508 - lr: 1.0000e-06\nEpoch 29/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2205 - acc: 0.9140 - recall_1: 0.3064 - precision_1: 0.6051 - iou: 0.2180 - dice_coef: 0.3566 - val_loss: 0.2030 - val_acc: 0.9204 - val_recall_1: 0.3173 - val_precision_1: 0.5901 - val_iou: 0.2169 - val_dice_coef: 0.3554 - lr: 1.0000e-06\nEpoch 30/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2190 - acc: 0.9144 - recall_1: 0.3102 - precision_1: 0.6094 - iou: 0.2202 - dice_coef: 0.3597 - val_loss: 0.2017 - val_acc: 0.9209 - val_recall_1: 0.3244 - val_precision_1: 0.5939 - val_iou: 0.2200 - val_dice_coef: 0.3596 - lr: 1.0000e-06\nEpoch 31/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.2175 - acc: 0.9149 - recall_1: 0.3141 - precision_1: 0.6135 - iou: 0.2225 - dice_coef: 0.3626 - val_loss: 0.2005 - val_acc: 0.9213 - val_recall_1: 0.3304 - val_precision_1: 0.5975 - val_iou: 0.2228 - val_dice_coef: 0.3634 - lr: 1.0000e-06\nEpoch 32/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2161 - acc: 0.9153 - recall_1: 0.3177 - precision_1: 0.6174 - iou: 0.2246 - dice_coef: 0.3655 - val_loss: 0.1993 - val_acc: 0.9218 - val_recall_1: 0.3360 - val_precision_1: 0.6011 - val_iou: 0.2255 - val_dice_coef: 0.3669 - lr: 1.0000e-06\nEpoch 33/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2148 - acc: 0.9158 - recall_1: 0.3213 - precision_1: 0.6212 - iou: 0.2268 - dice_coef: 0.3683 - val_loss: 0.1981 - val_acc: 0.9222 - val_recall_1: 0.3412 - val_precision_1: 0.6042 - val_iou: 0.2281 - val_dice_coef: 0.3703 - lr: 1.0000e-06\nEpoch 34/100\n31/31 [==============================] - 17s 553ms/step - loss: 0.2135 - acc: 0.9162 - recall_1: 0.3248 - precision_1: 0.6249 - iou: 0.2288 - dice_coef: 0.3711 - val_loss: 0.1969 - val_acc: 0.9226 - val_recall_1: 0.3462 - val_precision_1: 0.6076 - val_iou: 0.2305 - val_dice_coef: 0.3736 - lr: 1.0000e-06\nEpoch 35/100\n31/31 [==============================] - 17s 555ms/step - loss: 0.2122 - acc: 0.9166 - recall_1: 0.3282 - precision_1: 0.6284 - iou: 0.2309 - dice_coef: 0.3737 - val_loss: 0.1958 - val_acc: 0.9230 - val_recall_1: 0.3509 - val_precision_1: 0.6108 - val_iou: 0.2329 - val_dice_coef: 0.3767 - lr: 1.0000e-06\nEpoch 36/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.2109 - acc: 0.9170 - recall_1: 0.3315 - precision_1: 0.6318 - iou: 0.2329 - dice_coef: 0.3763 - val_loss: 0.1947 - val_acc: 0.9234 - val_recall_1: 0.3553 - val_precision_1: 0.6136 - val_iou: 0.2352 - val_dice_coef: 0.3797 - lr: 1.0000e-06\nEpoch 37/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2097 - acc: 0.9174 - recall_1: 0.3347 - precision_1: 0.6351 - iou: 0.2348 - dice_coef: 0.3789 - val_loss: 0.1936 - val_acc: 0.9238 - val_recall_1: 0.3596 - val_precision_1: 0.6166 - val_iou: 0.2374 - val_dice_coef: 0.3826 - lr: 1.0000e-06\nEpoch 38/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2086 - acc: 0.9178 - recall_1: 0.3379 - precision_1: 0.6383 - iou: 0.2367 - dice_coef: 0.3814 - val_loss: 0.1925 - val_acc: 0.9242 - val_recall_1: 0.3641 - val_precision_1: 0.6198 - val_iou: 0.2396 - val_dice_coef: 0.3854 - lr: 1.0000e-06\nEpoch 39/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.2074 - acc: 0.9181 - recall_1: 0.3409 - precision_1: 0.6414 - iou: 0.2386 - dice_coef: 0.3838 - val_loss: 0.1915 - val_acc: 0.9245 - val_recall_1: 0.3681 - val_precision_1: 0.6228 - val_iou: 0.2417 - val_dice_coef: 0.3881 - lr: 1.0000e-06\nEpoch 40/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.2063 - acc: 0.9185 - recall_1: 0.3440 - precision_1: 0.6445 - iou: 0.2404 - dice_coef: 0.3862 - val_loss: 0.1905 - val_acc: 0.9249 - val_recall_1: 0.3720 - val_precision_1: 0.6252 - val_iou: 0.2437 - val_dice_coef: 0.3907 - lr: 1.0000e-06\nEpoch 41/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.2052 - acc: 0.9189 - recall_1: 0.3469 - precision_1: 0.6475 - iou: 0.2423 - dice_coef: 0.3885 - val_loss: 0.1895 - val_acc: 0.9252 - val_recall_1: 0.3760 - val_precision_1: 0.6278 - val_iou: 0.2457 - val_dice_coef: 0.3933 - lr: 1.0000e-06\nEpoch 42/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.2041 - acc: 0.9192 - recall_1: 0.3498 - precision_1: 0.6503 - iou: 0.2441 - dice_coef: 0.3908 - val_loss: 0.1886 - val_acc: 0.9256 - val_recall_1: 0.3797 - val_precision_1: 0.6306 - val_iou: 0.2477 - val_dice_coef: 0.3958 - lr: 1.0000e-06\nEpoch 43/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2031 - acc: 0.9196 - recall_1: 0.3526 - precision_1: 0.6532 - iou: 0.2458 - dice_coef: 0.3931 - val_loss: 0.1877 - val_acc: 0.9260 - val_recall_1: 0.3834 - val_precision_1: 0.6334 - val_iou: 0.2496 - val_dice_coef: 0.3982 - lr: 1.0000e-06\nEpoch 44/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.2020 - acc: 0.9199 - recall_1: 0.3555 - precision_1: 0.6559 - iou: 0.2476 - dice_coef: 0.3953 - val_loss: 0.1868 - val_acc: 0.9263 - val_recall_1: 0.3869 - val_precision_1: 0.6360 - val_iou: 0.2514 - val_dice_coef: 0.4005 - lr: 1.0000e-06\nEpoch 45/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2010 - acc: 0.9202 - recall_1: 0.3582 - precision_1: 0.6586 - iou: 0.2493 - dice_coef: 0.3975 - val_loss: 0.1859 - val_acc: 0.9266 - val_recall_1: 0.3903 - val_precision_1: 0.6382 - val_iou: 0.2532 - val_dice_coef: 0.4028 - lr: 1.0000e-06\nEpoch 46/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.2001 - acc: 0.9206 - recall_1: 0.3609 - precision_1: 0.6612 - iou: 0.2510 - dice_coef: 0.3997 - val_loss: 0.1850 - val_acc: 0.9270 - val_recall_1: 0.3935 - val_precision_1: 0.6408 - val_iou: 0.2550 - val_dice_coef: 0.4051 - lr: 1.0000e-06\nEpoch 47/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1991 - acc: 0.9209 - recall_1: 0.3636 - precision_1: 0.6638 - iou: 0.2526 - dice_coef: 0.4018 - val_loss: 0.1842 - val_acc: 0.9273 - val_recall_1: 0.3968 - val_precision_1: 0.6430 - val_iou: 0.2567 - val_dice_coef: 0.4072 - lr: 1.0000e-06\nEpoch 48/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1981 - acc: 0.9212 - recall_1: 0.3662 - precision_1: 0.6664 - iou: 0.2543 - dice_coef: 0.4039 - val_loss: 0.1834 - val_acc: 0.9275 - val_recall_1: 0.3997 - val_precision_1: 0.6451 - val_iou: 0.2584 - val_dice_coef: 0.4094 - lr: 1.0000e-06\nEpoch 49/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1972 - acc: 0.9215 - recall_1: 0.3688 - precision_1: 0.6688 - iou: 0.2559 - dice_coef: 0.4060 - val_loss: 0.1826 - val_acc: 0.9279 - val_recall_1: 0.4030 - val_precision_1: 0.6476 - val_iou: 0.2601 - val_dice_coef: 0.4114 - lr: 1.0000e-06\nEpoch 50/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1963 - acc: 0.9218 - recall_1: 0.3714 - precision_1: 0.6713 - iou: 0.2576 - dice_coef: 0.4080 - val_loss: 0.1819 - val_acc: 0.9282 - val_recall_1: 0.4061 - val_precision_1: 0.6498 - val_iou: 0.2617 - val_dice_coef: 0.4135 - lr: 1.0000e-06\nEpoch 51/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1954 - acc: 0.9222 - recall_1: 0.3739 - precision_1: 0.6737 - iou: 0.2592 - dice_coef: 0.4100 - val_loss: 0.1811 - val_acc: 0.9285 - val_recall_1: 0.4090 - val_precision_1: 0.6517 - val_iou: 0.2633 - val_dice_coef: 0.4155 - lr: 1.0000e-06\nEpoch 52/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1945 - acc: 0.9224 - recall_1: 0.3764 - precision_1: 0.6759 - iou: 0.2608 - dice_coef: 0.4120 - val_loss: 0.1804 - val_acc: 0.9287 - val_recall_1: 0.4118 - val_precision_1: 0.6535 - val_iou: 0.2649 - val_dice_coef: 0.4175 - lr: 1.0000e-06\nEpoch 53/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1936 - acc: 0.9227 - recall_1: 0.3788 - precision_1: 0.6781 - iou: 0.2623 - dice_coef: 0.4140 - val_loss: 0.1797 - val_acc: 0.9290 - val_recall_1: 0.4145 - val_precision_1: 0.6556 - val_iou: 0.2664 - val_dice_coef: 0.4193 - lr: 1.0000e-06\nEpoch 54/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1927 - acc: 0.9230 - recall_1: 0.3812 - precision_1: 0.6803 - iou: 0.2639 - dice_coef: 0.4159 - val_loss: 0.1790 - val_acc: 0.9293 - val_recall_1: 0.4170 - val_precision_1: 0.6574 - val_iou: 0.2679 - val_dice_coef: 0.4212 - lr: 1.0000e-06\nEpoch 55/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1919 - acc: 0.9233 - recall_1: 0.3836 - precision_1: 0.6826 - iou: 0.2654 - dice_coef: 0.4179 - val_loss: 0.1783 - val_acc: 0.9295 - val_recall_1: 0.4196 - val_precision_1: 0.6593 - val_iou: 0.2694 - val_dice_coef: 0.4230 - lr: 1.0000e-06\nEpoch 56/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1910 - acc: 0.9236 - recall_1: 0.3860 - precision_1: 0.6847 - iou: 0.2670 - dice_coef: 0.4198 - val_loss: 0.1776 - val_acc: 0.9298 - val_recall_1: 0.4218 - val_precision_1: 0.6611 - val_iou: 0.2709 - val_dice_coef: 0.4248 - lr: 1.0000e-06\nEpoch 57/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1902 - acc: 0.9239 - recall_1: 0.3884 - precision_1: 0.6869 - iou: 0.2685 - dice_coef: 0.4217 - val_loss: 0.1770 - val_acc: 0.9300 - val_recall_1: 0.4243 - val_precision_1: 0.6628 - val_iou: 0.2723 - val_dice_coef: 0.4266 - lr: 1.0000e-06\nEpoch 58/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1894 - acc: 0.9242 - recall_1: 0.3908 - precision_1: 0.6889 - iou: 0.2700 - dice_coef: 0.4235 - val_loss: 0.1763 - val_acc: 0.9303 - val_recall_1: 0.4270 - val_precision_1: 0.6646 - val_iou: 0.2737 - val_dice_coef: 0.4283 - lr: 1.0000e-06\nEpoch 59/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1886 - acc: 0.9245 - recall_1: 0.3931 - precision_1: 0.6911 - iou: 0.2715 - dice_coef: 0.4254 - val_loss: 0.1757 - val_acc: 0.9305 - val_recall_1: 0.4295 - val_precision_1: 0.6662 - val_iou: 0.2751 - val_dice_coef: 0.4300 - lr: 1.0000e-06\nEpoch 60/100\n31/31 [==============================] - 17s 537ms/step - loss: 0.1878 - acc: 0.9248 - recall_1: 0.3954 - precision_1: 0.6931 - iou: 0.2730 - dice_coef: 0.4272 - val_loss: 0.1751 - val_acc: 0.9308 - val_recall_1: 0.4322 - val_precision_1: 0.6681 - val_iou: 0.2765 - val_dice_coef: 0.4317 - lr: 1.0000e-06\nEpoch 61/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1870 - acc: 0.9250 - recall_1: 0.3977 - precision_1: 0.6951 - iou: 0.2745 - dice_coef: 0.4290 - val_loss: 0.1745 - val_acc: 0.9310 - val_recall_1: 0.4346 - val_precision_1: 0.6698 - val_iou: 0.2779 - val_dice_coef: 0.4334 - lr: 1.0000e-06\nEpoch 62/100\n31/31 [==============================] - 17s 536ms/step - loss: 0.1862 - acc: 0.9253 - recall_1: 0.4000 - precision_1: 0.6970 - iou: 0.2760 - dice_coef: 0.4308 - val_loss: 0.1739 - val_acc: 0.9313 - val_recall_1: 0.4369 - val_precision_1: 0.6715 - val_iou: 0.2792 - val_dice_coef: 0.4350 - lr: 1.0000e-06\nEpoch 63/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1855 - acc: 0.9256 - recall_1: 0.4022 - precision_1: 0.6989 - iou: 0.2774 - dice_coef: 0.4326 - val_loss: 0.1734 - val_acc: 0.9315 - val_recall_1: 0.4390 - val_precision_1: 0.6730 - val_iou: 0.2805 - val_dice_coef: 0.4366 - lr: 1.0000e-06\nEpoch 64/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1847 - acc: 0.9258 - recall_1: 0.4044 - precision_1: 0.7007 - iou: 0.2789 - dice_coef: 0.4344 - val_loss: 0.1728 - val_acc: 0.9317 - val_recall_1: 0.4411 - val_precision_1: 0.6747 - val_iou: 0.2818 - val_dice_coef: 0.4381 - lr: 1.0000e-06\nEpoch 65/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1840 - acc: 0.9261 - recall_1: 0.4066 - precision_1: 0.7026 - iou: 0.2803 - dice_coef: 0.4361 - val_loss: 0.1723 - val_acc: 0.9320 - val_recall_1: 0.4434 - val_precision_1: 0.6763 - val_iou: 0.2831 - val_dice_coef: 0.4397 - lr: 1.0000e-06\nEpoch 66/100\n31/31 [==============================] - 17s 536ms/step - loss: 0.1832 - acc: 0.9264 - recall_1: 0.4088 - precision_1: 0.7045 - iou: 0.2818 - dice_coef: 0.4379 - val_loss: 0.1717 - val_acc: 0.9322 - val_recall_1: 0.4457 - val_precision_1: 0.6778 - val_iou: 0.2844 - val_dice_coef: 0.4412 - lr: 1.0000e-06\nEpoch 67/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1825 - acc: 0.9266 - recall_1: 0.4109 - precision_1: 0.7063 - iou: 0.2832 - dice_coef: 0.4396 - val_loss: 0.1712 - val_acc: 0.9324 - val_recall_1: 0.4478 - val_precision_1: 0.6792 - val_iou: 0.2856 - val_dice_coef: 0.4428 - lr: 1.0000e-06\nEpoch 68/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1818 - acc: 0.9269 - recall_1: 0.4130 - precision_1: 0.7081 - iou: 0.2846 - dice_coef: 0.4413 - val_loss: 0.1707 - val_acc: 0.9326 - val_recall_1: 0.4500 - val_precision_1: 0.6808 - val_iou: 0.2869 - val_dice_coef: 0.4443 - lr: 1.0000e-06\nEpoch 69/100\n31/31 [==============================] - 17s 537ms/step - loss: 0.1810 - acc: 0.9271 - recall_1: 0.4152 - precision_1: 0.7098 - iou: 0.2861 - dice_coef: 0.4431 - val_loss: 0.1702 - val_acc: 0.9329 - val_recall_1: 0.4521 - val_precision_1: 0.6821 - val_iou: 0.2881 - val_dice_coef: 0.4458 - lr: 1.0000e-06\nEpoch 70/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1803 - acc: 0.9274 - recall_1: 0.4173 - precision_1: 0.7116 - iou: 0.2875 - dice_coef: 0.4448 - val_loss: 0.1697 - val_acc: 0.9331 - val_recall_1: 0.4541 - val_precision_1: 0.6834 - val_iou: 0.2893 - val_dice_coef: 0.4472 - lr: 1.0000e-06\nEpoch 71/100\n31/31 [==============================] - 17s 556ms/step - loss: 0.1796 - acc: 0.9276 - recall_1: 0.4194 - precision_1: 0.7133 - iou: 0.2889 - dice_coef: 0.4465 - val_loss: 0.1692 - val_acc: 0.9333 - val_recall_1: 0.4561 - val_precision_1: 0.6847 - val_iou: 0.2905 - val_dice_coef: 0.4486 - lr: 1.0000e-06\nEpoch 72/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1789 - acc: 0.9279 - recall_1: 0.4215 - precision_1: 0.7150 - iou: 0.2903 - dice_coef: 0.4481 - val_loss: 0.1687 - val_acc: 0.9334 - val_recall_1: 0.4579 - val_precision_1: 0.6860 - val_iou: 0.2917 - val_dice_coef: 0.4500 - lr: 1.0000e-06\nEpoch 73/100\n31/31 [==============================] - 17s 554ms/step - loss: 0.1782 - acc: 0.9281 - recall_1: 0.4236 - precision_1: 0.7166 - iou: 0.2917 - dice_coef: 0.4498 - val_loss: 0.1682 - val_acc: 0.9337 - val_recall_1: 0.4599 - val_precision_1: 0.6873 - val_iou: 0.2929 - val_dice_coef: 0.4514 - lr: 1.0000e-06\nEpoch 74/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1775 - acc: 0.9284 - recall_1: 0.4256 - precision_1: 0.7183 - iou: 0.2931 - dice_coef: 0.4515 - val_loss: 0.1677 - val_acc: 0.9339 - val_recall_1: 0.4618 - val_precision_1: 0.6886 - val_iou: 0.2940 - val_dice_coef: 0.4528 - lr: 1.0000e-06\nEpoch 75/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1769 - acc: 0.9286 - recall_1: 0.4277 - precision_1: 0.7199 - iou: 0.2945 - dice_coef: 0.4531 - val_loss: 0.1673 - val_acc: 0.9340 - val_recall_1: 0.4636 - val_precision_1: 0.6898 - val_iou: 0.2952 - val_dice_coef: 0.4542 - lr: 1.0000e-06\nEpoch 76/100\n31/31 [==============================] - 17s 536ms/step - loss: 0.1762 - acc: 0.9289 - recall_1: 0.4298 - precision_1: 0.7214 - iou: 0.2958 - dice_coef: 0.4548 - val_loss: 0.1668 - val_acc: 0.9342 - val_recall_1: 0.4655 - val_precision_1: 0.6911 - val_iou: 0.2963 - val_dice_coef: 0.4555 - lr: 1.0000e-06\nEpoch 77/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1755 - acc: 0.9291 - recall_1: 0.4318 - precision_1: 0.7230 - iou: 0.2972 - dice_coef: 0.4564 - val_loss: 0.1664 - val_acc: 0.9344 - val_recall_1: 0.4670 - val_precision_1: 0.6923 - val_iou: 0.2975 - val_dice_coef: 0.4568 - lr: 1.0000e-06\nEpoch 78/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1749 - acc: 0.9294 - recall_1: 0.4338 - precision_1: 0.7246 - iou: 0.2986 - dice_coef: 0.4580 - val_loss: 0.1659 - val_acc: 0.9346 - val_recall_1: 0.4687 - val_precision_1: 0.6935 - val_iou: 0.2986 - val_dice_coef: 0.4581 - lr: 1.0000e-06\nEpoch 79/100\n31/31 [==============================] - 17s 536ms/step - loss: 0.1742 - acc: 0.9296 - recall_1: 0.4359 - precision_1: 0.7262 - iou: 0.3000 - dice_coef: 0.4597 - val_loss: 0.1655 - val_acc: 0.9348 - val_recall_1: 0.4703 - val_precision_1: 0.6947 - val_iou: 0.2997 - val_dice_coef: 0.4594 - lr: 1.0000e-06\nEpoch 80/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1736 - acc: 0.9298 - recall_1: 0.4379 - precision_1: 0.7277 - iou: 0.3014 - dice_coef: 0.4613 - val_loss: 0.1651 - val_acc: 0.9350 - val_recall_1: 0.4717 - val_precision_1: 0.6961 - val_iou: 0.3007 - val_dice_coef: 0.4607 - lr: 1.0000e-06\nEpoch 81/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1729 - acc: 0.9301 - recall_1: 0.4399 - precision_1: 0.7291 - iou: 0.3027 - dice_coef: 0.4629 - val_loss: 0.1647 - val_acc: 0.9351 - val_recall_1: 0.4734 - val_precision_1: 0.6970 - val_iou: 0.3018 - val_dice_coef: 0.4619 - lr: 1.0000e-06\nEpoch 82/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1723 - acc: 0.9303 - recall_1: 0.4420 - precision_1: 0.7306 - iou: 0.3041 - dice_coef: 0.4645 - val_loss: 0.1643 - val_acc: 0.9353 - val_recall_1: 0.4748 - val_precision_1: 0.6981 - val_iou: 0.3028 - val_dice_coef: 0.4632 - lr: 1.0000e-06\nEpoch 83/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1716 - acc: 0.9306 - recall_1: 0.4440 - precision_1: 0.7321 - iou: 0.3055 - dice_coef: 0.4661 - val_loss: 0.1639 - val_acc: 0.9354 - val_recall_1: 0.4764 - val_precision_1: 0.6992 - val_iou: 0.3039 - val_dice_coef: 0.4644 - lr: 1.0000e-06\nEpoch 84/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1710 - acc: 0.9308 - recall_1: 0.4461 - precision_1: 0.7336 - iou: 0.3068 - dice_coef: 0.4677 - val_loss: 0.1635 - val_acc: 0.9356 - val_recall_1: 0.4779 - val_precision_1: 0.7002 - val_iou: 0.3050 - val_dice_coef: 0.4657 - lr: 1.0000e-06\nEpoch 85/100\n31/31 [==============================] - 17s 554ms/step - loss: 0.1704 - acc: 0.9310 - recall_1: 0.4481 - precision_1: 0.7350 - iou: 0.3082 - dice_coef: 0.4693 - val_loss: 0.1631 - val_acc: 0.9358 - val_recall_1: 0.4795 - val_precision_1: 0.7014 - val_iou: 0.3060 - val_dice_coef: 0.4669 - lr: 1.0000e-06\nEpoch 86/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1697 - acc: 0.9313 - recall_1: 0.4501 - precision_1: 0.7365 - iou: 0.3096 - dice_coef: 0.4709 - val_loss: 0.1627 - val_acc: 0.9360 - val_recall_1: 0.4813 - val_precision_1: 0.7026 - val_iou: 0.3071 - val_dice_coef: 0.4681 - lr: 1.0000e-06\nEpoch 87/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1691 - acc: 0.9315 - recall_1: 0.4521 - precision_1: 0.7379 - iou: 0.3109 - dice_coef: 0.4724 - val_loss: 0.1623 - val_acc: 0.9361 - val_recall_1: 0.4828 - val_precision_1: 0.7037 - val_iou: 0.3081 - val_dice_coef: 0.4693 - lr: 1.0000e-06\nEpoch 88/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1685 - acc: 0.9317 - recall_1: 0.4542 - precision_1: 0.7392 - iou: 0.3123 - dice_coef: 0.4740 - val_loss: 0.1619 - val_acc: 0.9363 - val_recall_1: 0.4844 - val_precision_1: 0.7047 - val_iou: 0.3091 - val_dice_coef: 0.4705 - lr: 1.0000e-06\nEpoch 89/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1679 - acc: 0.9320 - recall_1: 0.4562 - precision_1: 0.7406 - iou: 0.3136 - dice_coef: 0.4756 - val_loss: 0.1615 - val_acc: 0.9365 - val_recall_1: 0.4860 - val_precision_1: 0.7058 - val_iou: 0.3102 - val_dice_coef: 0.4717 - lr: 1.0000e-06\nEpoch 90/100\n31/31 [==============================] - 17s 553ms/step - loss: 0.1673 - acc: 0.9322 - recall_1: 0.4582 - precision_1: 0.7419 - iou: 0.3150 - dice_coef: 0.4771 - val_loss: 0.1612 - val_acc: 0.9366 - val_recall_1: 0.4874 - val_precision_1: 0.7069 - val_iou: 0.3111 - val_dice_coef: 0.4728 - lr: 1.0000e-06\nEpoch 91/100\n31/31 [==============================] - 17s 536ms/step - loss: 0.1667 - acc: 0.9324 - recall_1: 0.4602 - precision_1: 0.7433 - iou: 0.3163 - dice_coef: 0.4787 - val_loss: 0.1608 - val_acc: 0.9368 - val_recall_1: 0.4888 - val_precision_1: 0.7078 - val_iou: 0.3121 - val_dice_coef: 0.4740 - lr: 1.0000e-06\nEpoch 92/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1661 - acc: 0.9326 - recall_1: 0.4622 - precision_1: 0.7445 - iou: 0.3177 - dice_coef: 0.4803 - val_loss: 0.1605 - val_acc: 0.9369 - val_recall_1: 0.4903 - val_precision_1: 0.7087 - val_iou: 0.3131 - val_dice_coef: 0.4751 - lr: 1.0000e-06\nEpoch 93/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1655 - acc: 0.9329 - recall_1: 0.4642 - precision_1: 0.7459 - iou: 0.3190 - dice_coef: 0.4818 - val_loss: 0.1601 - val_acc: 0.9371 - val_recall_1: 0.4917 - val_precision_1: 0.7098 - val_iou: 0.3141 - val_dice_coef: 0.4763 - lr: 1.0000e-06\nEpoch 94/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1649 - acc: 0.9331 - recall_1: 0.4663 - precision_1: 0.7472 - iou: 0.3204 - dice_coef: 0.4834 - val_loss: 0.1598 - val_acc: 0.9372 - val_recall_1: 0.4931 - val_precision_1: 0.7108 - val_iou: 0.3151 - val_dice_coef: 0.4774 - lr: 1.0000e-06\nEpoch 95/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1643 - acc: 0.9333 - recall_1: 0.4683 - precision_1: 0.7485 - iou: 0.3218 - dice_coef: 0.4849 - val_loss: 0.1594 - val_acc: 0.9374 - val_recall_1: 0.4943 - val_precision_1: 0.7117 - val_iou: 0.3161 - val_dice_coef: 0.4786 - lr: 1.0000e-06\nEpoch 96/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1637 - acc: 0.9336 - recall_1: 0.4703 - precision_1: 0.7498 - iou: 0.3231 - dice_coef: 0.4865 - val_loss: 0.1591 - val_acc: 0.9375 - val_recall_1: 0.4955 - val_precision_1: 0.7125 - val_iou: 0.3171 - val_dice_coef: 0.4797 - lr: 1.0000e-06\nEpoch 97/100\n31/31 [==============================] - 17s 551ms/step - loss: 0.1631 - acc: 0.9338 - recall_1: 0.4723 - precision_1: 0.7511 - iou: 0.3245 - dice_coef: 0.4880 - val_loss: 0.1587 - val_acc: 0.9377 - val_recall_1: 0.4970 - val_precision_1: 0.7134 - val_iou: 0.3181 - val_dice_coef: 0.4808 - lr: 1.0000e-06\nEpoch 98/100\n31/31 [==============================] - 17s 535ms/step - loss: 0.1625 - acc: 0.9340 - recall_1: 0.4743 - precision_1: 0.7523 - iou: 0.3258 - dice_coef: 0.4896 - val_loss: 0.1584 - val_acc: 0.9378 - val_recall_1: 0.4983 - val_precision_1: 0.7144 - val_iou: 0.3190 - val_dice_coef: 0.4820 - lr: 1.0000e-06\nEpoch 99/100\n31/31 [==============================] - 17s 534ms/step - loss: 0.1619 - acc: 0.9342 - recall_1: 0.4763 - precision_1: 0.7536 - iou: 0.3272 - dice_coef: 0.4911 - val_loss: 0.1581 - val_acc: 0.9380 - val_recall_1: 0.4995 - val_precision_1: 0.7155 - val_iou: 0.3200 - val_dice_coef: 0.4831 - lr: 1.0000e-06\nEpoch 100/100\n31/31 [==============================] - 17s 552ms/step - loss: 0.1614 - acc: 0.9345 - recall_1: 0.4782 - precision_1: 0.7548 - iou: 0.3286 - dice_coef: 0.4926 - val_loss: 0.1577 - val_acc: 0.9381 - val_recall_1: 0.5008 - val_precision_1: 0.7163 - val_iou: 0.3210 - val_dice_coef: 0.4842 - lr: 1.0000e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_image_new(path):\n    \n    x = cv2.imread(path , cv2.IMREAD_COLOR)\n    x = cv2.resize(x , (256, 256))\n    x = x/255.0\n    # size is 256, 256 , 3\n    return x\n\n\ndef read_mask_new(path):\n\n    x = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x , (256, 256))\n    # size is 256, 256\n    x = np.expand_dims(x, axis = -1)\n    # size is 256, 256 , 1\n    \n    return x\n\ndef mask_parse(mask):\n    \n    mask = np.squeeze(mask)\n    mask = [mask , mask , mask]\n    \n    mask = np.transpose(mask , (1,2,0))\n    return mask","metadata":{"execution":{"iopub.status.busy":"2023-08-29T22:00:08.845624Z","iopub.execute_input":"2023-08-29T22:00:08.846497Z","iopub.status.idle":"2023-08-29T22:00:08.855504Z","shell.execute_reply.started":"2023-08-29T22:00:08.846460Z","shell.execute_reply":"2023-08-29T22:00:08.854556Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom tensorflow.keras.utils import CustomObjectScope\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T22:00:08.859483Z","iopub.execute_input":"2023-08-29T22:00:08.859772Z","iopub.status.idle":"2023-08-29T22:00:08.874076Z","shell.execute_reply.started":"2023-08-29T22:00:08.859747Z","shell.execute_reply":"2023-08-29T22:00:08.873118Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    test_dataset = tf_dataset(test_x , test_y , batch = batch)\n    test_steps = len(test_x) // batch\n    \n    if len(test_x)%batch != 0 :\n        test_steps +=1\n        \n    with CustomObjectScope({'iou' : iou , 'dice_coef' : dice_coef ,  'dice_coef_loss' :dice_coef_loss }):\n    \n        model = tf.keras.models.load_model(\"/kaggle/working/model.h5\")\n        \n    model.evaluate(test_dataset , steps = test_steps)\n    \n    for i , (x,y) in tqdm(enumerate(zip(test_x , test_y)) , total= len(test_x)):\n        \n        x = read_image_new(x)\n        y = read_mask_new(y)\n        \n        y_pred = model.predict(np.expand_dims(x , axis = 0))\n        \n        y_pred= y_pred[0] > 0.5\n        \n        h,w, _ = x.shape\n        \n        white_line = np.ones((h,10,3)) * 255.0\n        \n        all_images = [\n            \n            x*255.0, white_line,\n            \n            mask_parse(y) , white_line,\n            mask_parse(y_pred)*255.0\n            \n        ]\n        \n        image = np.concatenate (all_images, axis =1)\n        cv2.imwrite(f\"/kaggle/working/{i}.png\" , image)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T22:00:08.875439Z","iopub.execute_input":"2023-08-29T22:00:08.875923Z","iopub.status.idle":"2023-08-29T22:00:16.780902Z","shell.execute_reply.started":"2023-08-29T22:00:08.875889Z","shell.execute_reply":"2023-08-29T22:00:16.779905Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 1s 175ms/step - loss: 0.1753 - acc: 0.9312 - recall_1: 0.4838 - precision_1: 0.7317 - iou: 0.3274 - dice_coef: 0.4933\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/61 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 312ms/step\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 1/61 [00:00<00:22,  2.62it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"  5%|▍         | 3/61 [00:00<00:09,  6.36it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 5/61 [00:00<00:06,  8.63it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 27ms/step\n","output_type":"stream"},{"name":"stderr","text":" 11%|█▏        | 7/61 [00:00<00:05,  9.68it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▍        | 9/61 [00:01<00:04, 10.83it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 11/61 [00:01<00:04, 11.49it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 21%|██▏       | 13/61 [00:01<00:04, 11.77it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 15/61 [00:01<00:03, 12.05it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 17/61 [00:01<00:03, 12.16it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 19/61 [00:01<00:03, 12.28it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 21/61 [00:01<00:03, 12.26it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 23/61 [00:02<00:03, 12.23it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 25/61 [00:02<00:03, 11.71it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 40ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 27/61 [00:02<00:03, 11.25it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 29/61 [00:02<00:02, 11.67it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 31/61 [00:02<00:02, 11.86it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 33/61 [00:03<00:02, 11.87it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 35/61 [00:03<00:02, 12.14it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 37/61 [00:03<00:01, 12.51it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 39/61 [00:03<00:01, 12.46it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 41/61 [00:03<00:01, 12.38it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 43/61 [00:03<00:01, 12.35it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 45/61 [00:03<00:01, 12.38it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 47/61 [00:04<00:01, 12.32it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 49/61 [00:04<00:00, 12.18it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▎ | 51/61 [00:04<00:00, 12.24it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 53/61 [00:04<00:00, 12.43it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 55/61 [00:04<00:00, 12.42it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 57/61 [00:04<00:00, 12.61it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 59/61 [00:05<00:00, 12.64it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 61/61 [00:05<00:00, 11.63it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-29T22:00:16.782444Z","iopub.execute_input":"2023-08-29T22:00:16.783082Z","iopub.status.idle":"2023-08-29T22:00:16.789977Z","shell.execute_reply.started":"2023-08-29T22:00:16.783045Z","shell.execute_reply":"2023-08-29T22:00:16.788910Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(256, 256, 1)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !zip -r segmentation_model.zip  \"/kaggle/input/segmentation-model\"","metadata":{"execution":{"iopub.status.busy":"2023-08-29T22:00:16.793139Z","iopub.execute_input":"2023-08-29T22:00:16.793418Z","iopub.status.idle":"2023-08-29T22:00:16.800614Z","shell.execute_reply.started":"2023-08-29T22:00:16.793394Z","shell.execute_reply":"2023-08-29T22:00:16.799635Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"!zip -r cvc_new_new.zip   \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2023-08-29T22:36:15.810273Z","iopub.execute_input":"2023-08-29T22:36:15.810704Z","iopub.status.idle":"2023-08-29T22:36:23.198162Z","shell.execute_reply.started":"2023-08-29T22:36:15.810655Z","shell.execute_reply":"2023-08-29T22:36:23.196719Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/10.png (deflated 6%)\n  adding: kaggle/working/18.png (deflated 7%)\n  adding: kaggle/working/45.png (deflated 5%)\n  adding: kaggle/working/16.png (deflated 7%)\n  adding: kaggle/working/38.png (deflated 7%)\n  adding: kaggle/working/27.png (deflated 7%)\n  adding: kaggle/working/32.png (deflated 9%)\n  adding: kaggle/working/59.png (deflated 5%)\n  adding: kaggle/working/7.png (deflated 6%)\n  adding: kaggle/working/0.png (deflated 6%)\n  adding: kaggle/working/cvc_new.zip (stored 0%)\n  adding: kaggle/working/49.png (deflated 7%)\n  adding: kaggle/working/1.png (deflated 7%)\n  adding: kaggle/working/50.png (deflated 7%)\n  adding: kaggle/working/52.png (deflated 6%)\n  adding: kaggle/working/5.png (deflated 6%)\n  adding: kaggle/working/29.png (deflated 8%)\n  adding: kaggle/working/44.png (deflated 5%)\n  adding: kaggle/working/11.png (deflated 7%)\n  adding: kaggle/working/35.png (deflated 5%)\n  adding: kaggle/working/9.png (deflated 7%)\n  adding: kaggle/working/24.png (deflated 6%)\n  adding: kaggle/working/53.png (deflated 8%)\n  adding: kaggle/working/37.png (deflated 9%)\n  adding: kaggle/working/14.png (deflated 7%)\n  adding: kaggle/working/23.png (deflated 7%)\n  adding: kaggle/working/46.png (deflated 6%)\n  adding: kaggle/working/26.png (deflated 6%)\n  adding: kaggle/working/6.png (deflated 6%)\n  adding: kaggle/working/48.png (deflated 7%)\n  adding: kaggle/working/cvc.zip (stored 0%)\n  adding: kaggle/working/47.png (deflated 5%)\n  adding: kaggle/working/4.png (deflated 6%)\n  adding: kaggle/working/8.png (deflated 8%)\n  adding: kaggle/working/22.png (deflated 6%)\n  adding: kaggle/working/40.png (deflated 5%)\n  adding: kaggle/working/56.png (deflated 8%)\n  adding: kaggle/working/33.png (deflated 5%)\n  adding: kaggle/working/13.png (deflated 5%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/57.png (deflated 6%)\n  adding: kaggle/working/43.png (deflated 7%)\n  adding: kaggle/working/28.png (deflated 5%)\n  adding: kaggle/working/25.png (deflated 7%)\n  adding: kaggle/working/31.png (deflated 6%)\n  adding: kaggle/working/58.png (deflated 8%)\n  adding: kaggle/working/20.png (deflated 7%)\n  adding: kaggle/working/21.png (deflated 6%)\n  adding: kaggle/working/41.png (deflated 6%)\n  adding: kaggle/working/55.png (deflated 6%)\n  adding: kaggle/working/54.png (deflated 6%)\n  adding: kaggle/working/42.png (deflated 9%)\n  adding: kaggle/working/36.png (deflated 8%)\n  adding: kaggle/working/2.png (deflated 6%)\n  adding: kaggle/working/30.png (deflated 5%)\n  adding: kaggle/working/60.png (deflated 6%)\n  adding: kaggle/working/12.png (deflated 6%)\n  adding: kaggle/working/model.h5 (deflated 8%)\n  adding: kaggle/working/19.png (deflated 7%)\n  adding: kaggle/working/3.png (deflated 5%)\n  adding: kaggle/working/34.png (deflated 6%)\n  adding: kaggle/working/39.png (deflated 5%)\n  adding: kaggle/working/51.png (deflated 9%)\n  adding: kaggle/working/17.png (deflated 5%)\n  adding: kaggle/working/15.png (deflated 5%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}