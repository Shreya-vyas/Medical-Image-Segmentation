{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# data loading \n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import Recall, Precision\n\nH = 256\nW = 256\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef shuffling(x, y):\n    x, y = shuffle(x, y, random_state=42)\n    return x, y\n\ndef load_data(dataset_path):\n    split = 0.1\n    images = sorted(glob(os.path.join(dataset_path, \"trainx\", \"*.bmp\")))\n    masks = sorted(glob(os.path.join(dataset_path, \"trainy\", \"*.bmp\")))\n\n    test_size = int(len(images) * split)\n\n    train_x, valid_x = train_test_split(images, test_size=test_size, random_state=42)\n    train_y, valid_y = train_test_split(masks, test_size=test_size, random_state=42)\n\n    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-01T19:44:31.732788Z","iopub.execute_input":"2023-09-01T19:44:31.733611Z","iopub.status.idle":"2023-09-01T19:44:42.161370Z","shell.execute_reply.started":"2023-09-01T19:44:31.733578Z","shell.execute_reply":"2023-09-01T19:44:42.160348Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef read_image(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_COLOR)  ## (H, W, 3)\n    x = cv2.resize(x, (W, H))\n    x = x/255.0\n    x = x.astype(np.float32)\n    return x                                ## (256, 256, 3)\n\ndef read_mask(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (H, W)\n    x = cv2.resize(x, (W, H))\n    x = x/255.0\n    x = x.astype(np.float32)                    ## (256, 256)\n    x = np.expand_dims(x, axis=-1)              ## (256, 256, 1)\n    return x\n\ndef tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n    x.set_shape([H, W, 3])\n    y.set_shape([H, W, 1])\n    return x, y\n\ndef tf_dataset(X, Y, batch):\n    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.prefetch(10)\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T19:44:42.163492Z","iopub.execute_input":"2023-09-01T19:44:42.164495Z","iopub.status.idle":"2023-09-01T19:44:42.176030Z","shell.execute_reply.started":"2023-09-01T19:44:42.164458Z","shell.execute_reply":"2023-09-01T19:44:42.174980Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# metrics \n\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef iou(y_true, y_pred):\n    def f(y_true, y_pred):\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        x = (intersection + 1e-15) / (union + 1e-15)\n        x = x.astype(np.float32)\n        return x\n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\nsmooth = 1e-15\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T19:44:42.177207Z","iopub.execute_input":"2023-09-01T19:44:42.178396Z","iopub.status.idle":"2023-09-01T19:44:42.193245Z","shell.execute_reply.started":"2023-09-01T19:44:42.178362Z","shell.execute_reply":"2023-09-01T19:44:42.192287Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Input, ZeroPadding2D\nfrom tensorflow.keras.models import Model\n\ndef batchnorm_relu(inputs):\n    x = BatchNormalization()(inputs)\n    x = Activation(\"relu\")(x)\n    return x\n\ndef residual_block(inputs, num_filters, strides=1):\n    \"\"\" Convolutional Layer \"\"\"\n    x = batchnorm_relu(inputs)\n    x = Conv2D(num_filters, 3, padding=\"same\", strides=strides)(x)\n    x = batchnorm_relu(x)\n    x = Conv2D(num_filters, 3, padding=\"same\", strides=1)(x)\n\n    \"\"\" Shortcut Connection \"\"\"\n    s = Conv2D(num_filters, 1, padding=\"same\", strides=strides)(inputs)\n    x = x + s\n    return x\n\ndef decoder_block(inputs, skip_features, num_filters):\n    x = UpSampling2D((2, 2))(inputs)\n    x = Concatenate()([x, skip_features])\n    x = residual_block(x, num_filters, strides=1)\n    return x\n\ndef build_resunet(input_shape):\n    inputs = Input(input_shape)\n\n    \"\"\" Encoder 1 \"\"\"\n    x = Conv2D(64, 3, padding=\"same\", strides=1)(inputs)\n    x = batchnorm_relu(x)\n    x = Conv2D(64, 3, padding=\"same\", strides=1)(x)\n    s = Conv2D(64, 1, padding=\"same\", strides=1)(inputs)\n    s1 = x + s\n\n    \"\"\" Encoder 2 and 3 \"\"\"\n    s2 = residual_block(s1, 128, strides=2)\n    s3 = residual_block(s2, 256, strides=2)\n\n    \"\"\" Bridge \"\"\"\n    b = residual_block(s3, 512, strides=2)\n\n    \"\"\" Decoder 1, 2, 3 \"\"\"\n    d1 = decoder_block(b, s3, 256)\n    d2 = decoder_block(d1, s2, 128)\n    d3 = decoder_block(d2, s1, 64)\n\n    \"\"\" Classifier \"\"\"\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n\n    \"\"\" Model \"\"\"\n    model = Model(inputs, outputs)\n    return model\n\nif __name__ == \"__main__\":\n    model = build_resunet((256, 256, 3))\n    model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T19:44:42.197376Z","iopub.execute_input":"2023-09-01T19:44:42.198342Z","iopub.status.idle":"2023-09-01T19:44:45.798887Z","shell.execute_reply.started":"2023-09-01T19:44:42.198309Z","shell.execute_reply":"2023-09-01T19:44:45.798158Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n                                )                                                                 \n                                                                                                  \n batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n alization)                     )                                                                 \n                                                                                                  \n activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n                                )                                                                 \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 256, 256, 64  256         ['input_1[0][0]']                \n                                )                                                                 \n                                                                                                  \n tf.__operators__.add (TFOpLamb  (None, 256, 256, 64  0          ['conv2d_1[0][0]',               \n da)                            )                                 'conv2d_2[0][0]']               \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['tf.__operators__.add[0][0]']   \n rmalization)                   )                                                                 \n                                                                                                  \n activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n                                )                                                                 \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 128, 128, 12  73856       ['activation_1[0][0]']           \n                                8)                                                                \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n rmalization)                   8)                                                                \n                                                                                                  \n activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n                                8)                                                                \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n                                8)                                                                \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 128, 128, 12  8320        ['tf.__operators__.add[0][0]']   \n                                8)                                                                \n                                                                                                  \n tf.__operators__.add_1 (TFOpLa  (None, 128, 128, 12  0          ['conv2d_4[0][0]',               \n mbda)                          8)                                'conv2d_5[0][0]']               \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['tf.__operators__.add_1[0][0]'] \n rmalization)                   8)                                                                \n                                                                                                  \n activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n                                8)                                                                \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 64, 64, 256)  295168      ['activation_3[0][0]']           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 64, 64, 256)  33024       ['tf.__operators__.add_1[0][0]'] \n                                                                                                  \n tf.__operators__.add_2 (TFOpLa  (None, 64, 64, 256)  0          ['conv2d_7[0][0]',               \n mbda)                                                            'conv2d_8[0][0]']               \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['tf.__operators__.add_2[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 32, 32, 512)  1180160     ['activation_5[0][0]']           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_9[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 32, 32, 512)  131584      ['tf.__operators__.add_2[0][0]'] \n                                                                                                  \n tf.__operators__.add_3 (TFOpLa  (None, 32, 32, 512)  0          ['conv2d_10[0][0]',              \n mbda)                                                            'conv2d_11[0][0]']              \n                                                                                                  \n up_sampling2d (UpSampling2D)   (None, 64, 64, 512)  0           ['tf.__operators__.add_3[0][0]'] \n                                                                                                  \n concatenate (Concatenate)      (None, 64, 64, 768)  0           ['up_sampling2d[0][0]',          \n                                                                  'tf.__operators__.add_2[0][0]'] \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 64, 64, 768)  3072       ['concatenate[0][0]']            \n rmalization)                                                                                     \n                                                                                                  \n activation_7 (Activation)      (None, 64, 64, 768)  0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 64, 64, 256)  1769728     ['activation_7[0][0]']           \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n rmalization)                                                                                     \n                                                                                                  \n activation_8 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_8[0][0]']           \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 64, 64, 256)  196864      ['concatenate[0][0]']            \n                                                                                                  \n tf.__operators__.add_4 (TFOpLa  (None, 64, 64, 256)  0          ['conv2d_13[0][0]',              \n mbda)                                                            'conv2d_14[0][0]']              \n                                                                                                  \n up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 25  0          ['tf.__operators__.add_4[0][0]'] \n                                6)                                                                \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_1[0][0]',        \n                                4)                                'tf.__operators__.add_1[0][0]'] \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 128, 128, 38  1536       ['concatenate_1[0][0]']          \n rmalization)                   4)                                                                \n                                                                                                  \n activation_9 (Activation)      (None, 128, 128, 38  0           ['batch_normalization_9[0][0]']  \n                                4)                                                                \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 128, 128, 12  442496      ['activation_9[0][0]']           \n                                8)                                                                \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n ormalization)                  8)                                                                \n                                                                                                  \n activation_10 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_10[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 128, 128, 12  147584      ['activation_10[0][0]']          \n                                8)                                                                \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 128, 128, 12  49280       ['concatenate_1[0][0]']          \n                                8)                                                                \n                                                                                                  \n tf.__operators__.add_5 (TFOpLa  (None, 128, 128, 12  0          ['conv2d_16[0][0]',              \n mbda)                          8)                                'conv2d_17[0][0]']              \n                                                                                                  \n up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 12  0          ['tf.__operators__.add_5[0][0]'] \n                                8)                                                                \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_2[0][0]',        \n                                2)                                'tf.__operators__.add[0][0]']   \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 256, 256, 19  768        ['concatenate_2[0][0]']          \n ormalization)                  2)                                                                \n                                                                                                  \n activation_11 (Activation)     (None, 256, 256, 19  0           ['batch_normalization_11[0][0]'] \n                                2)                                                                \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 256, 256, 64  110656      ['activation_11[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 256, 256, 64  256        ['conv2d_18[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_12 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_12[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_19 (Conv2D)             (None, 256, 256, 64  36928       ['activation_12[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_20 (Conv2D)             (None, 256, 256, 64  12352       ['concatenate_2[0][0]']          \n                                )                                                                 \n                                                                                                  \n tf.__operators__.add_6 (TFOpLa  (None, 256, 256, 64  0          ['conv2d_19[0][0]',              \n mbda)                          )                                 'conv2d_20[0][0]']              \n                                                                                                  \n conv2d_21 (Conv2D)             (None, 256, 256, 1)  65          ['tf.__operators__.add_6[0][0]'] \n                                                                                                  \n==================================================================================================\nTotal params: 8,227,393\nTrainable params: 8,220,993\nNon-trainable params: 6,400\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Folder for saving data \"\"\"\n    create_dir(\"files\")\n\n    \"\"\" Hyperparameters \"\"\"\n    batch_size = 16\n    lr = 1e-4 ## (0.0001)\n    num_epoch = 100\n    model_path = \"files/model.h5\"\n    csv_path = \"files/data.csv\"\n\n    dataset_path = \"/kaggle/input/ph2-resized\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n\n    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n    print(f\"Test: {len(test_x)} - {len(test_y)}\")\n\n    train_dataset = tf_dataset(train_x, train_y, batch_size)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch_size)\n\n    train_steps = len(train_x)//batch_size\n    valid_steps = len(valid_x)//batch_size\n\n    if len(train_x) % batch_size != 0:\n        train_steps += 1\n\n    if len(valid_x) % batch_size != 0:\n        valid_steps += 1\n\n    \"\"\" Model \"\"\"\n    model = build_resunet((H, W, 3))\n    metrics = [dice_coef, iou, Recall(), Precision()]\n    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr), metrics=metrics)\n    model.summary()\n\n    callbacks = [\n        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, min_lr=1e-7, verbose=1),\n        CSVLogger(csv_path),\n        TensorBoard(),\n        EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=False)\n    ]\n\n    model.fit(\n        train_dataset,\n        epochs=num_epoch,\n        validation_data=valid_dataset,\n        steps_per_epoch=train_steps,\n        validation_steps=valid_steps,\n        callbacks=callbacks\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-01T19:44:45.799935Z","iopub.execute_input":"2023-09-01T19:44:45.800298Z","iopub.status.idle":"2023-09-01T19:49:10.277447Z","shell.execute_reply.started":"2023-09-01T19:44:45.800263Z","shell.execute_reply":"2023-09-01T19:49:10.276538Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Train: 160 - 160\nValid: 20 - 20\nTest: 20 - 20\nModel: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d_22 (Conv2D)             (None, 256, 256, 64  1792        ['input_2[0][0]']                \n                                )                                                                 \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 256, 256, 64  256        ['conv2d_22[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_13 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_13[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_23 (Conv2D)             (None, 256, 256, 64  36928       ['activation_13[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_24 (Conv2D)             (None, 256, 256, 64  256         ['input_2[0][0]']                \n                                )                                                                 \n                                                                                                  \n tf.__operators__.add_7 (TFOpLa  (None, 256, 256, 64  0          ['conv2d_23[0][0]',              \n mbda)                          )                                 'conv2d_24[0][0]']              \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 256, 256, 64  256        ['tf.__operators__.add_7[0][0]'] \n ormalization)                  )                                                                 \n                                                                                                  \n activation_14 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_14[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_25 (Conv2D)             (None, 128, 128, 12  73856       ['activation_14[0][0]']          \n                                8)                                                                \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_25[0][0]']              \n ormalization)                  8)                                                                \n                                                                                                  \n activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_26 (Conv2D)             (None, 128, 128, 12  147584      ['activation_15[0][0]']          \n                                8)                                                                \n                                                                                                  \n conv2d_27 (Conv2D)             (None, 128, 128, 12  8320        ['tf.__operators__.add_7[0][0]'] \n                                8)                                                                \n                                                                                                  \n tf.__operators__.add_8 (TFOpLa  (None, 128, 128, 12  0          ['conv2d_26[0][0]',              \n mbda)                          8)                                'conv2d_27[0][0]']              \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 128, 128, 12  512        ['tf.__operators__.add_8[0][0]'] \n ormalization)                  8)                                                                \n                                                                                                  \n activation_16 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_16[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_28 (Conv2D)             (None, 64, 64, 256)  295168      ['activation_16[0][0]']          \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_28[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_17 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_17[0][0]'] \n                                                                                                  \n conv2d_29 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_17[0][0]']          \n                                                                                                  \n conv2d_30 (Conv2D)             (None, 64, 64, 256)  33024       ['tf.__operators__.add_8[0][0]'] \n                                                                                                  \n tf.__operators__.add_9 (TFOpLa  (None, 64, 64, 256)  0          ['conv2d_29[0][0]',              \n mbda)                                                            'conv2d_30[0][0]']              \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 64, 64, 256)  1024       ['tf.__operators__.add_9[0][0]'] \n ormalization)                                                                                    \n                                                                                                  \n activation_18 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_18[0][0]'] \n                                                                                                  \n conv2d_31 (Conv2D)             (None, 32, 32, 512)  1180160     ['activation_18[0][0]']          \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_31[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_19 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_19[0][0]'] \n                                                                                                  \n conv2d_32 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_19[0][0]']          \n                                                                                                  \n conv2d_33 (Conv2D)             (None, 32, 32, 512)  131584      ['tf.__operators__.add_9[0][0]'] \n                                                                                                  \n tf.__operators__.add_10 (TFOpL  (None, 32, 32, 512)  0          ['conv2d_32[0][0]',              \n ambda)                                                           'conv2d_33[0][0]']              \n                                                                                                  \n up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 512)  0          ['tf.__operators__.add_10[0][0]']\n                                                                                                  \n concatenate_3 (Concatenate)    (None, 64, 64, 768)  0           ['up_sampling2d_3[0][0]',        \n                                                                  'tf.__operators__.add_9[0][0]'] \n                                                                                                  \n batch_normalization_20 (BatchN  (None, 64, 64, 768)  3072       ['concatenate_3[0][0]']          \n ormalization)                                                                                    \n                                                                                                  \n activation_20 (Activation)     (None, 64, 64, 768)  0           ['batch_normalization_20[0][0]'] \n                                                                                                  \n conv2d_34 (Conv2D)             (None, 64, 64, 256)  1769728     ['activation_20[0][0]']          \n                                                                                                  \n batch_normalization_21 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_34[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_21 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_21[0][0]'] \n                                                                                                  \n conv2d_35 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_21[0][0]']          \n                                                                                                  \n conv2d_36 (Conv2D)             (None, 64, 64, 256)  196864      ['concatenate_3[0][0]']          \n                                                                                                  \n tf.__operators__.add_11 (TFOpL  (None, 64, 64, 256)  0          ['conv2d_35[0][0]',              \n ambda)                                                           'conv2d_36[0][0]']              \n                                                                                                  \n up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 25  0          ['tf.__operators__.add_11[0][0]']\n                                6)                                                                \n                                                                                                  \n concatenate_4 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_4[0][0]',        \n                                4)                                'tf.__operators__.add_8[0][0]'] \n                                                                                                  \n batch_normalization_22 (BatchN  (None, 128, 128, 38  1536       ['concatenate_4[0][0]']          \n ormalization)                  4)                                                                \n                                                                                                  \n activation_22 (Activation)     (None, 128, 128, 38  0           ['batch_normalization_22[0][0]'] \n                                4)                                                                \n                                                                                                  \n conv2d_37 (Conv2D)             (None, 128, 128, 12  442496      ['activation_22[0][0]']          \n                                8)                                                                \n                                                                                                  \n batch_normalization_23 (BatchN  (None, 128, 128, 12  512        ['conv2d_37[0][0]']              \n ormalization)                  8)                                                                \n                                                                                                  \n activation_23 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_23[0][0]'] \n                                8)                                                                \n                                                                                                  \n conv2d_38 (Conv2D)             (None, 128, 128, 12  147584      ['activation_23[0][0]']          \n                                8)                                                                \n                                                                                                  \n conv2d_39 (Conv2D)             (None, 128, 128, 12  49280       ['concatenate_4[0][0]']          \n                                8)                                                                \n                                                                                                  \n tf.__operators__.add_12 (TFOpL  (None, 128, 128, 12  0          ['conv2d_38[0][0]',              \n ambda)                         8)                                'conv2d_39[0][0]']              \n                                                                                                  \n up_sampling2d_5 (UpSampling2D)  (None, 256, 256, 12  0          ['tf.__operators__.add_12[0][0]']\n                                8)                                                                \n                                                                                                  \n concatenate_5 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_5[0][0]',        \n                                2)                                'tf.__operators__.add_7[0][0]'] \n                                                                                                  \n batch_normalization_24 (BatchN  (None, 256, 256, 19  768        ['concatenate_5[0][0]']          \n ormalization)                  2)                                                                \n                                                                                                  \n activation_24 (Activation)     (None, 256, 256, 19  0           ['batch_normalization_24[0][0]'] \n                                2)                                                                \n                                                                                                  \n conv2d_40 (Conv2D)             (None, 256, 256, 64  110656      ['activation_24[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_25 (BatchN  (None, 256, 256, 64  256        ['conv2d_40[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_25 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_25[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_41 (Conv2D)             (None, 256, 256, 64  36928       ['activation_25[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_42 (Conv2D)             (None, 256, 256, 64  12352       ['concatenate_5[0][0]']          \n                                )                                                                 \n                                                                                                  \n tf.__operators__.add_13 (TFOpL  (None, 256, 256, 64  0          ['conv2d_41[0][0]',              \n ambda)                         )                                 'conv2d_42[0][0]']              \n                                                                                                  \n conv2d_43 (Conv2D)             (None, 256, 256, 1)  65          ['tf.__operators__.add_13[0][0]']\n                                                                                                  \n==================================================================================================\nTotal params: 8,227,393\nTrainable params: 8,220,993\nNon-trainable params: 6,400\n__________________________________________________________________________________________________\nEpoch 1/100\n10/10 [==============================] - ETA: 0s - loss: 0.6943 - dice_coef: 0.6945 - iou: 0.5457 - recall: 0.7069 - precision: 0.7174\nEpoch 1: val_loss improved from inf to 0.62268, saving model to files/model.h5\n10/10 [==============================] - 39s 822ms/step - loss: 0.6943 - dice_coef: 0.6945 - iou: 0.5457 - recall: 0.7069 - precision: 0.7174 - val_loss: 0.6227 - val_dice_coef: 0.3384 - val_iou: 0.2038 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 2/100\n10/10 [==============================] - ETA: 0s - loss: 0.3412 - dice_coef: 0.7979 - iou: 0.6654 - recall: 0.7922 - precision: 0.8449\nEpoch 2: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 534ms/step - loss: 0.3412 - dice_coef: 0.7979 - iou: 0.6654 - recall: 0.7922 - precision: 0.8449 - val_loss: 0.6422 - val_dice_coef: 0.3311 - val_iou: 0.1985 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 3/100\n10/10 [==============================] - ETA: 0s - loss: 0.2755 - dice_coef: 0.7870 - iou: 0.6494 - recall: 0.7944 - precision: 0.8713\nEpoch 3: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 537ms/step - loss: 0.2755 - dice_coef: 0.7870 - iou: 0.6494 - recall: 0.7944 - precision: 0.8713 - val_loss: 0.6707 - val_dice_coef: 0.3086 - val_iou: 0.1825 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 4/100\n10/10 [==============================] - ETA: 0s - loss: 0.2455 - dice_coef: 0.8207 - iou: 0.6966 - recall: 0.8361 - precision: 0.8752\nEpoch 4: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 533ms/step - loss: 0.2455 - dice_coef: 0.8207 - iou: 0.6966 - recall: 0.8361 - precision: 0.8752 - val_loss: 0.7403 - val_dice_coef: 0.2588 - val_iou: 0.1486 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 5/100\n10/10 [==============================] - ETA: 0s - loss: 0.2085 - dice_coef: 0.8303 - iou: 0.7116 - recall: 0.8477 - precision: 0.8936\nEpoch 5: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 534ms/step - loss: 0.2085 - dice_coef: 0.8303 - iou: 0.7116 - recall: 0.8477 - precision: 0.8936 - val_loss: 0.7214 - val_dice_coef: 0.2653 - val_iou: 0.1530 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 6/100\n10/10 [==============================] - ETA: 0s - loss: 0.1909 - dice_coef: 0.8424 - iou: 0.7285 - recall: 0.8603 - precision: 0.9073\nEpoch 6: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 534ms/step - loss: 0.1909 - dice_coef: 0.8424 - iou: 0.7285 - recall: 0.8603 - precision: 0.9073 - val_loss: 0.7731 - val_dice_coef: 0.2289 - val_iou: 0.1293 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 7/100\n10/10 [==============================] - ETA: 0s - loss: 0.1760 - dice_coef: 0.8462 - iou: 0.7347 - recall: 0.8682 - precision: 0.9110\nEpoch 7: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 536ms/step - loss: 0.1760 - dice_coef: 0.8462 - iou: 0.7347 - recall: 0.8682 - precision: 0.9110 - val_loss: 0.7933 - val_dice_coef: 0.2166 - val_iou: 0.1215 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 8/100\n10/10 [==============================] - ETA: 0s - loss: 0.1644 - dice_coef: 0.8557 - iou: 0.7488 - recall: 0.8784 - precision: 0.9200\nEpoch 8: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 534ms/step - loss: 0.1644 - dice_coef: 0.8557 - iou: 0.7488 - recall: 0.8784 - precision: 0.9200 - val_loss: 0.8251 - val_dice_coef: 0.1987 - val_iou: 0.1103 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 9/100\n10/10 [==============================] - ETA: 0s - loss: 0.1549 - dice_coef: 0.8623 - iou: 0.7589 - recall: 0.8858 - precision: 0.9240\nEpoch 9: val_loss did not improve from 0.62268\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n10/10 [==============================] - 5s 536ms/step - loss: 0.1549 - dice_coef: 0.8623 - iou: 0.7589 - recall: 0.8858 - precision: 0.9240 - val_loss: 0.8862 - val_dice_coef: 0.1701 - val_iou: 0.0930 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\nEpoch 10/100\n10/10 [==============================] - ETA: 0s - loss: 0.1401 - dice_coef: 0.8721 - iou: 0.7740 - recall: 0.8865 - precision: 0.9399\nEpoch 10: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 533ms/step - loss: 0.1401 - dice_coef: 0.8721 - iou: 0.7740 - recall: 0.8865 - precision: 0.9399 - val_loss: 0.8723 - val_dice_coef: 0.1761 - val_iou: 0.0966 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\nEpoch 11/100\n10/10 [==============================] - ETA: 0s - loss: 0.1376 - dice_coef: 0.8735 - iou: 0.7761 - recall: 0.9081 - precision: 0.9261\nEpoch 11: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 537ms/step - loss: 0.1376 - dice_coef: 0.8735 - iou: 0.7761 - recall: 0.9081 - precision: 0.9261 - val_loss: 0.9099 - val_dice_coef: 0.1602 - val_iou: 0.0871 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\nEpoch 12/100\n10/10 [==============================] - ETA: 0s - loss: 0.1360 - dice_coef: 0.8750 - iou: 0.7785 - recall: 0.8942 - precision: 0.9388\nEpoch 12: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 537ms/step - loss: 0.1360 - dice_coef: 0.8750 - iou: 0.7785 - recall: 0.8942 - precision: 0.9388 - val_loss: 0.9501 - val_dice_coef: 0.1447 - val_iou: 0.0780 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\nEpoch 13/100\n10/10 [==============================] - ETA: 0s - loss: 0.1346 - dice_coef: 0.8757 - iou: 0.7797 - recall: 0.8988 - precision: 0.9369\nEpoch 13: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 534ms/step - loss: 0.1346 - dice_coef: 0.8757 - iou: 0.7797 - recall: 0.8988 - precision: 0.9369 - val_loss: 0.9633 - val_dice_coef: 0.1400 - val_iou: 0.0753 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\nEpoch 14/100\n10/10 [==============================] - ETA: 0s - loss: 0.1333 - dice_coef: 0.8764 - iou: 0.7807 - recall: 0.9027 - precision: 0.9357\nEpoch 14: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 536ms/step - loss: 0.1333 - dice_coef: 0.8764 - iou: 0.7807 - recall: 0.9027 - precision: 0.9357 - val_loss: 0.9955 - val_dice_coef: 0.1291 - val_iou: 0.0690 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\nEpoch 15/100\n10/10 [==============================] - ETA: 0s - loss: 0.1322 - dice_coef: 0.8773 - iou: 0.7821 - recall: 0.9001 - precision: 0.9390\nEpoch 15: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 535ms/step - loss: 0.1322 - dice_coef: 0.8773 - iou: 0.7821 - recall: 0.9001 - precision: 0.9390 - val_loss: 1.0235 - val_dice_coef: 0.1204 - val_iou: 0.0641 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\nEpoch 16/100\n10/10 [==============================] - ETA: 0s - loss: 0.1309 - dice_coef: 0.8783 - iou: 0.7836 - recall: 0.9029 - precision: 0.9384\nEpoch 16: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 536ms/step - loss: 0.1309 - dice_coef: 0.8783 - iou: 0.7836 - recall: 0.9029 - precision: 0.9384 - val_loss: 1.0470 - val_dice_coef: 0.1137 - val_iou: 0.0603 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\nEpoch 17/100\n10/10 [==============================] - ETA: 0s - loss: 0.1297 - dice_coef: 0.8793 - iou: 0.7852 - recall: 0.9037 - precision: 0.9392\nEpoch 17: val_loss did not improve from 0.62268\n\nEpoch 17: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n10/10 [==============================] - 5s 533ms/step - loss: 0.1297 - dice_coef: 0.8793 - iou: 0.7852 - recall: 0.9037 - precision: 0.9392 - val_loss: 1.0745 - val_dice_coef: 0.1063 - val_iou: 0.0561 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\nEpoch 18/100\n10/10 [==============================] - ETA: 0s - loss: 0.1282 - dice_coef: 0.8803 - iou: 0.7868 - recall: 0.9052 - precision: 0.9397\nEpoch 18: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 536ms/step - loss: 0.1282 - dice_coef: 0.8803 - iou: 0.7868 - recall: 0.9052 - precision: 0.9397 - val_loss: 1.0942 - val_dice_coef: 0.1013 - val_iou: 0.0534 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\nEpoch 19/100\n10/10 [==============================] - ETA: 0s - loss: 0.1281 - dice_coef: 0.8804 - iou: 0.7870 - recall: 0.9051 - precision: 0.9400\nEpoch 19: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 534ms/step - loss: 0.1281 - dice_coef: 0.8804 - iou: 0.7870 - recall: 0.9051 - precision: 0.9400 - val_loss: 1.1121 - val_dice_coef: 0.0970 - val_iou: 0.0510 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\nEpoch 20/100\n10/10 [==============================] - ETA: 0s - loss: 0.1280 - dice_coef: 0.8805 - iou: 0.7872 - recall: 0.9050 - precision: 0.9402\nEpoch 20: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 537ms/step - loss: 0.1280 - dice_coef: 0.8805 - iou: 0.7872 - recall: 0.9050 - precision: 0.9402 - val_loss: 1.1279 - val_dice_coef: 0.0934 - val_iou: 0.0490 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\nEpoch 21/100\n10/10 [==============================] - ETA: 0s - loss: 0.1278 - dice_coef: 0.8806 - iou: 0.7874 - recall: 0.9050 - precision: 0.9403\nEpoch 21: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 532ms/step - loss: 0.1278 - dice_coef: 0.8806 - iou: 0.7874 - recall: 0.9050 - precision: 0.9403 - val_loss: 1.1415 - val_dice_coef: 0.0904 - val_iou: 0.0474 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\nEpoch 22/100\n10/10 [==============================] - ETA: 0s - loss: 0.1277 - dice_coef: 0.8808 - iou: 0.7876 - recall: 0.9051 - precision: 0.9404\nEpoch 22: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 536ms/step - loss: 0.1277 - dice_coef: 0.8808 - iou: 0.7876 - recall: 0.9051 - precision: 0.9404 - val_loss: 1.1529 - val_dice_coef: 0.0881 - val_iou: 0.0461 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\nEpoch 23/100\n10/10 [==============================] - ETA: 0s - loss: 0.1276 - dice_coef: 0.8809 - iou: 0.7878 - recall: 0.9052 - precision: 0.9405\nEpoch 23: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 537ms/step - loss: 0.1276 - dice_coef: 0.8809 - iou: 0.7878 - recall: 0.9052 - precision: 0.9405 - val_loss: 1.1618 - val_dice_coef: 0.0864 - val_iou: 0.0452 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\nEpoch 24/100\n10/10 [==============================] - ETA: 0s - loss: 0.1274 - dice_coef: 0.8810 - iou: 0.7880 - recall: 0.9054 - precision: 0.9405\nEpoch 24: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 537ms/step - loss: 0.1274 - dice_coef: 0.8810 - iou: 0.7880 - recall: 0.9054 - precision: 0.9405 - val_loss: 1.1681 - val_dice_coef: 0.0854 - val_iou: 0.0446 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\nEpoch 25/100\n10/10 [==============================] - ETA: 0s - loss: 0.1273 - dice_coef: 0.8811 - iou: 0.7882 - recall: 0.9055 - precision: 0.9406\nEpoch 25: val_loss did not improve from 0.62268\n\nEpoch 25: ReduceLROnPlateau reducing learning rate to 1e-07.\n10/10 [==============================] - 5s 533ms/step - loss: 0.1273 - dice_coef: 0.8811 - iou: 0.7882 - recall: 0.9055 - precision: 0.9406 - val_loss: 1.1711 - val_dice_coef: 0.0851 - val_iou: 0.0445 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\nEpoch 26/100\n10/10 [==============================] - ETA: 0s - loss: 0.1271 - dice_coef: 0.8812 - iou: 0.7884 - recall: 0.9058 - precision: 0.9406\nEpoch 26: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 536ms/step - loss: 0.1271 - dice_coef: 0.8812 - iou: 0.7884 - recall: 0.9058 - precision: 0.9406 - val_loss: 1.1696 - val_dice_coef: 0.0859 - val_iou: 0.0449 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\nEpoch 27/100\n10/10 [==============================] - ETA: 0s - loss: 0.1271 - dice_coef: 0.8813 - iou: 0.7884 - recall: 0.9058 - precision: 0.9406\nEpoch 27: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 538ms/step - loss: 0.1271 - dice_coef: 0.8813 - iou: 0.7884 - recall: 0.9058 - precision: 0.9406 - val_loss: 1.1637 - val_dice_coef: 0.0879 - val_iou: 0.0460 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\nEpoch 28/100\n10/10 [==============================] - ETA: 0s - loss: 0.1271 - dice_coef: 0.8813 - iou: 0.7884 - recall: 0.9058 - precision: 0.9406\nEpoch 28: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 532ms/step - loss: 0.1271 - dice_coef: 0.8813 - iou: 0.7884 - recall: 0.9058 - precision: 0.9406 - val_loss: 1.1531 - val_dice_coef: 0.0915 - val_iou: 0.0480 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\nEpoch 29/100\n10/10 [==============================] - ETA: 0s - loss: 0.1271 - dice_coef: 0.8813 - iou: 0.7884 - recall: 0.9058 - precision: 0.9406\nEpoch 29: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 534ms/step - loss: 0.1271 - dice_coef: 0.8813 - iou: 0.7884 - recall: 0.9058 - precision: 0.9406 - val_loss: 1.1371 - val_dice_coef: 0.0971 - val_iou: 0.0511 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\nEpoch 30/100\n10/10 [==============================] - ETA: 0s - loss: 0.1270 - dice_coef: 0.8813 - iou: 0.7885 - recall: 0.9058 - precision: 0.9406\nEpoch 30: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 537ms/step - loss: 0.1270 - dice_coef: 0.8813 - iou: 0.7885 - recall: 0.9058 - precision: 0.9406 - val_loss: 1.1151 - val_dice_coef: 0.1054 - val_iou: 0.0557 - val_recall: 7.7006e-05 - val_precision: 0.0077 - lr: 1.0000e-07\nEpoch 31/100\n10/10 [==============================] - ETA: 0s - loss: 0.1270 - dice_coef: 0.8813 - iou: 0.7885 - recall: 0.9058 - precision: 0.9406\nEpoch 31: val_loss did not improve from 0.62268\n10/10 [==============================] - 5s 536ms/step - loss: 0.1270 - dice_coef: 0.8813 - iou: 0.7885 - recall: 0.9058 - precision: 0.9406 - val_loss: 1.0865 - val_dice_coef: 0.1173 - val_iou: 0.0625 - val_recall: 0.0012 - val_precision: 0.0714 - lr: 1.0000e-07\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.utils import CustomObjectScope\nfrom sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n\n\nH = 256\nW = 256\n\ndef read_image(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)  ## (H, W, 3)\n    x = cv2.resize(x, (W, H))\n    ori_x = x\n    x = x/255.0\n    x = x.astype(np.float32)\n    x = np.expand_dims(x, axis=0)\n    return ori_x, x                                ## (1, 256, 256, 3)\n\n\ndef read_mask(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (H, W)\n    x = cv2.resize(x, (W, H))\n    ori_x = x\n    x = x/255.0\n    x = x.astype(np.int32)                    ## (256, 256)\n    return ori_x, x\n\ndef save_results(ori_x, ori_y, y_pred, save_image_path):\n    line = np.ones((H, 10, 3)) * 255\n\n    ori_y = np.expand_dims(ori_y, axis=-1)  ## (256, 256, 1)\n    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1) ## (256, 256, 3)\n\n    y_pred = np.expand_dims(y_pred, axis=-1)  ## (256, 256, 1)\n    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) ## (256, 256, 3)\n\n    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred*255], axis=1)\n    cv2.imwrite(save_image_path, cat_images)\n\n\nif __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Folder for saving results \"\"\"\n    create_dir(\"results\")\n\n    \"\"\" Load the model \"\"\"\n    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n        model = tf.keras.models.load_model(\"/kaggle/working/files/model.h5\")\n\n    \"\"\" Load the test data \"\"\"\n    dataset_path = \"/kaggle/input/ph2-resized\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n\n    SCORE = []\n    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n        \"\"\" Exctracting the image name \"\"\"\n        name = x.split(\"/\")[-1]\n\n        \"\"\" Read the image and mask \"\"\"\n        ori_x, x = read_image(x)\n        ori_y, y = read_mask(y)\n\n        \"\"\" Predicting the mask \"\"\"\n        y_pred = model.predict(x)[0] > 0.5\n        y_pred = np.squeeze(y_pred, axis=-1)\n        y_pred = y_pred.astype(np.int32)\n\n        \"\"\" Saving the predicted mask \"\"\"\n        save_image_path = f\"results/{name}\"\n        save_results(ori_x, ori_y, y_pred, save_image_path)\n\n        \"\"\" Flatten the array \"\"\"\n        y = y.flatten()\n        y_pred = y_pred.flatten()\n\n        \"\"\" Calculating metrics values \"\"\"\n        acc_value = accuracy_score(y, y_pred)\n        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n\n    \"\"\" mean metrics values \"\"\"\n    score = [s[1:] for s in SCORE]\n    score = np.mean(score, axis=0)\n    print(f\"Accuracy: {score[0]:0.5f}\")\n    print(f\"F1: {score[1]:0.5f}\")\n    print(f\"Jaccard: {score[2]:0.5f}\")\n    print(f\"Recall: {score[3]:0.5f}\")\n    print(f\"Precision: {score[4]:0.5f}\")\n\n    df = pd.DataFrame(SCORE, columns = [\"Image Name\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n    df.to_csv(\"files/score.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-01T19:49:10.279058Z","iopub.execute_input":"2023-09-01T19:49:10.279637Z","iopub.status.idle":"2023-09-01T19:49:15.673094Z","shell.execute_reply.started":"2023-09-01T19:49:10.279602Z","shell.execute_reply":"2023-09-01T19:49:15.672128Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"  0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 1s 958ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n  5%|▌         | 1/20 [00:01<00:21,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 21ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 10%|█         | 2/20 [00:01<00:10,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 15%|█▌        | 3/20 [00:01<00:06,  2.64it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 21ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 20%|██        | 4/20 [00:01<00:04,  3.37it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 21ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 25%|██▌       | 5/20 [00:01<00:03,  4.02it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 30%|███       | 6/20 [00:01<00:03,  4.49it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 35%|███▌      | 7/20 [00:02<00:02,  4.98it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 40%|████      | 8/20 [00:02<00:02,  5.21it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 45%|████▌     | 9/20 [00:02<00:01,  5.53it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 50%|█████     | 10/20 [00:02<00:01,  5.56it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 21ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 55%|█████▌    | 11/20 [00:02<00:01,  5.73it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 60%|██████    | 12/20 [00:02<00:01,  5.73it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 65%|██████▌   | 13/20 [00:03<00:01,  5.78it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 70%|███████   | 14/20 [00:03<00:01,  5.70it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 75%|███████▌  | 15/20 [00:03<00:00,  5.62it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 80%|████████  | 16/20 [00:03<00:00,  5.55it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 85%|████████▌ | 17/20 [00:03<00:00,  5.74it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 90%|█████████ | 18/20 [00:04<00:00,  5.81it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n 95%|█████████▌| 19/20 [00:04<00:00,  5.86it/s]","output_type":"stream"},{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n100%|██████████| 20/20 [00:04<00:00,  4.61it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.78860\nF1: 0.00000\nJaccard: 0.00000\nRecall: 0.00000\nPrecision: 0.00000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r skin_lesion_resunet_new.zip   \"/kaggle/working/results\"","metadata":{"execution":{"iopub.status.busy":"2023-09-01T19:49:15.674799Z","iopub.execute_input":"2023-09-01T19:49:15.675475Z","iopub.status.idle":"2023-09-01T19:49:16.942586Z","shell.execute_reply.started":"2023-09-01T19:49:15.675439Z","shell.execute_reply":"2023-09-01T19:49:16.941515Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/results/ (stored 0%)\n  adding: kaggle/working/results/X_img_122.bmp (deflated 70%)\n  adding: kaggle/working/results/X_img_33.bmp (deflated 70%)\n  adding: kaggle/working/results/X_img_129.bmp (deflated 71%)\n  adding: kaggle/working/results/X_img_40.bmp (deflated 69%)\n  adding: kaggle/working/results/X_img_156.bmp (deflated 78%)\n  adding: kaggle/working/results/X_img_126.bmp (deflated 70%)\n  adding: kaggle/working/results/X_img_121.bmp (deflated 70%)\n  adding: kaggle/working/results/X_img_29.bmp (deflated 73%)\n  adding: kaggle/working/results/X_img_192.bmp (deflated 71%)\n  adding: kaggle/working/results/X_img_90.bmp (deflated 70%)\n  adding: kaggle/working/results/X_img_15.bmp (deflated 72%)\n  adding: kaggle/working/results/X_img_58.bmp (deflated 71%)\n  adding: kaggle/working/results/X_img_93.bmp (deflated 70%)\n  adding: kaggle/working/results/X_img_7.bmp (deflated 72%)\n  adding: kaggle/working/results/X_img_26.bmp (deflated 68%)\n  adding: kaggle/working/results/X_img_153.bmp (deflated 74%)\n  adding: kaggle/working/results/X_img_147.bmp (deflated 72%)\n  adding: kaggle/working/results/X_img_57.bmp (deflated 72%)\n  adding: kaggle/working/results/X_img_167.bmp (deflated 70%)\n  adding: kaggle/working/results/X_img_146.bmp (deflated 71%)\n","output_type":"stream"}]}]}