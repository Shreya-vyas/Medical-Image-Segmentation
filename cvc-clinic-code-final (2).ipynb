{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:34.564896Z","iopub.execute_input":"2023-08-21T17:36:34.565186Z","iopub.status.idle":"2023-08-21T17:36:34.727525Z","shell.execute_reply.started":"2023-08-21T17:36:34.565161Z","shell.execute_reply":"2023-08-21T17:36:34.726625Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:34.729454Z","iopub.execute_input":"2023-08-21T17:36:34.729862Z","iopub.status.idle":"2023-08-21T17:36:44.317087Z","shell.execute_reply.started":"2023-08-21T17:36:34.729830Z","shell.execute_reply":"2023-08-21T17:36:44.316091Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# loading dataset\n\ndef load_data(path , split = 0.1):\n    \n    images = sorted(glob(os.path.join(path , \"PNG/Original/*\")))\n    \n    masks = sorted(glob(os.path.join(path , \"PNG/Ground Truth/*\")))\n    \n    total_size = len(images)\n    valid_size = int(split * total_size)\n    test_size = int(split * total_size)\n    \n    # 612 total \n    # 61 test\n    # 61 validate\n    \n    train_x , valid_x = train_test_split(images , test_size = valid_size, random_state = 42)\n    \n    train_y , valid_y = train_test_split(masks , test_size = valid_size, random_state = 42)\n    \n    \n    train_x , test_x = train_test_split(train_x , test_size = test_size, random_state = 42)\n    \n    train_y , test_y = train_test_split(train_y , test_size = test_size, random_state = 42)\n    \n    return (train_x , train_y ) , (valid_x , valid_y) , (test_x , test_y)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-21T17:36:44.320423Z","iopub.execute_input":"2023-08-21T17:36:44.321865Z","iopub.status.idle":"2023-08-21T17:36:44.329987Z","shell.execute_reply.started":"2023-08-21T17:36:44.321827Z","shell.execute_reply":"2023-08-21T17:36:44.328730Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def read_image(path):\n    \n    path = path.decode()\n    x = cv2.imread(path , cv2.IMREAD_COLOR)\n    x = cv2.resize(x , (256, 256))\n    x = x/255.0\n    # size is 256, 256 , 3\n    return x\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:44.333952Z","iopub.execute_input":"2023-08-21T17:36:44.334306Z","iopub.status.idle":"2023-08-21T17:36:44.341383Z","shell.execute_reply.started":"2023-08-21T17:36:44.334281Z","shell.execute_reply":"2023-08-21T17:36:44.340422Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def read_mask(path):\n    \n    path = path.decode()\n    x = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x , (256, 256))\n    x = x/255.0\n    # size is 256, 256\n    x = np.expand_dims(x, axis = -1)\n    # size is 256, 256 , 1\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:44.342567Z","iopub.execute_input":"2023-08-21T17:36:44.342980Z","iopub.status.idle":"2023-08-21T17:36:44.352176Z","shell.execute_reply.started":"2023-08-21T17:36:44.342947Z","shell.execute_reply":"2023-08-21T17:36:44.351147Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def tf_parse (x,y) :\n    \n    def _parse(x,y):\n        \n        x = read_image(x)\n        y = read_mask(y)\n        \n        return x,y\n    x,y = tf.numpy_function(_parse , [x,y] , [tf.float64 , tf.float64])\n    \n    x.set_shape([256,256,3])\n    y.set_shape([256,256,1])\n    \n    return x,y","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:44.353231Z","iopub.execute_input":"2023-08-21T17:36:44.353502Z","iopub.status.idle":"2023-08-21T17:36:44.362344Z","shell.execute_reply.started":"2023-08-21T17:36:44.353457Z","shell.execute_reply":"2023-08-21T17:36:44.361404Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def tf_dataset(x,y,batch = 8):\n    \n    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:44.365595Z","iopub.execute_input":"2023-08-21T17:36:44.365884Z","iopub.status.idle":"2023-08-21T17:36:44.372714Z","shell.execute_reply.started":"2023-08-21T17:36:44.365852Z","shell.execute_reply":"2023-08-21T17:36:44.371524Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    path = \"/kaggle/input/cvcclinicdb\"\n    (train_x , train_y ) , (valid_x , valid_y) , (test_x , test_y) = load_data(path,0.1)\n    \n    # 612 total \n    # 61 test\n    # 61 validate\n    # 490 train\n    \n    ds = tf_dataset(test_x , test_y)\n    \n    for x, y in ds:\n        \n        print(x.shape , y.shape) # batch of 8 images with 8 img and 8 masks\n        break","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:44.373972Z","iopub.execute_input":"2023-08-21T17:36:44.374597Z","iopub.status.idle":"2023-08-21T17:36:47.847642Z","shell.execute_reply.started":"2023-08-21T17:36:44.374563Z","shell.execute_reply":"2023-08-21T17:36:47.846665Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(8, 256, 256, 3) (8, 256, 256, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# unet arch code\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D , BatchNormalization, Activation, Concatenate,UpSampling2D, Input, MaxPool2D\nfrom tensorflow.keras.models import Model\n\n\ndef conv_block(x , num_filters) :\n    \n    x = Conv2D(num_filters , (3,3) , padding= \"same\" ) (x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    \n    x = Conv2D(num_filters , (3,3) , padding= \"same\" ) (x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    \n    return x\n\n\ndef build_model():\n    \n    size = 256\n    \n    num_filters= [16,32,64,128]\n    \n    inputs = Input(shape = (size,size,3))\n    \n    skip_x = []\n    x = inputs\n    \n    for f in num_filters:\n        x = conv_block(x,f)\n        skip_x.append(x)\n        x = MaxPool2D((2,2))(x)\n    # bridge\n    \n    x = conv_block(x,num_filters[-1])\n    \n    num_filters.reverse()\n    \n    skip_x.reverse()\n    \n    for i , f in enumerate(num_filters):\n        \n        x = UpSampling2D((2,2))(x)\n        xs = skip_x[i]\n        x = Concatenate()([x,xs])\n        x = conv_block(x,f)\n        \n    x = Conv2D(1,(1,1) , padding=\"same\")(x)\n    x = Activation(\"sigmoid\") (x)\n    \n    return Model(inputs,x)\n\nif __name__ == \"__main__\":\n    \n    model = build_model()\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:47.849302Z","iopub.execute_input":"2023-08-21T17:36:47.849660Z","iopub.status.idle":"2023-08-21T17:36:48.497189Z","shell.execute_reply.started":"2023-08-21T17:36:47.849627Z","shell.execute_reply":"2023-08-21T17:36:48.496440Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 256, 256, 16  448         ['input_1[0][0]']                \n                                )                                                                 \n                                                                                                  \n batch_normalization (BatchNorm  (None, 256, 256, 16  64         ['conv2d[0][0]']                 \n alization)                     )                                                                 \n                                                                                                  \n activation (Activation)        (None, 256, 256, 16  0           ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 256, 256, 16  2320        ['activation[0][0]']             \n                                )                                                                 \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 256, 256, 16  64         ['conv2d_1[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n activation_1 (Activation)      (None, 256, 256, 16  0           ['batch_normalization_1[0][0]']  \n                                )                                                                 \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['activation_1[0][0]']           \n                                )                                                                 \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 128, 128, 32  4640        ['max_pooling2d[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 128, 128, 32  128        ['conv2d_2[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n activation_2 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_2[0][0]']  \n                                )                                                                 \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 128, 128, 32  9248        ['activation_2[0][0]']           \n                                )                                                                 \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 128, 128, 32  128        ['conv2d_3[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n activation_3 (Activation)      (None, 128, 128, 32  0           ['batch_normalization_3[0][0]']  \n                                )                                                                 \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['activation_3[0][0]']           \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 64, 64, 64)   36928       ['activation_4[0][0]']           \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_5[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_5 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['activation_5[0][0]']           \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_2[0][0]']        \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_6[0][0]']           \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_7[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_7 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0          ['activation_7[0][0]']           \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 16, 16, 128)  147584      ['max_pooling2d_3[0][0]']        \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_8[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_8 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 16, 16, 128)  147584      ['activation_8[0][0]']           \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_9[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_9 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n up_sampling2d (UpSampling2D)   (None, 32, 32, 128)  0           ['activation_9[0][0]']           \n                                                                                                  \n concatenate (Concatenate)      (None, 32, 32, 256)  0           ['up_sampling2d[0][0]',          \n                                                                  'activation_7[0][0]']           \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 32, 32, 128)  295040      ['concatenate[0][0]']            \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 32, 32, 128)  512        ['conv2d_10[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_10 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_10[0][0]']          \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 32, 32, 128)  512        ['conv2d_11[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_11 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 128)  0          ['activation_11[0][0]']          \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 64, 64, 192)  0           ['up_sampling2d_1[0][0]',        \n                                                                  'activation_5[0][0]']           \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 64, 64, 64)   110656      ['concatenate_1[0][0]']          \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 64, 64, 64)  256         ['conv2d_12[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_12 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_12[0][0]']          \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 64, 64, 64)  256         ['conv2d_13[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_13 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_13[0][0]'] \n                                                                                                  \n up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 64  0          ['activation_13[0][0]']          \n                                )                                                                 \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 128, 128, 96  0           ['up_sampling2d_2[0][0]',        \n                                )                                 'activation_3[0][0]']           \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 128, 128, 32  27680       ['concatenate_2[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_14[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_14 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_14[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 128, 128, 32  9248        ['activation_14[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 128, 128, 32  128        ['conv2d_15[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_15 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_15[0][0]'] \n                                )                                                                 \n                                                                                                  \n up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 32  0          ['activation_15[0][0]']          \n                                )                                                                 \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 256, 256, 48  0           ['up_sampling2d_3[0][0]',        \n                                )                                 'activation_1[0][0]']           \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 256, 256, 16  6928        ['concatenate_3[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 256, 256, 16  64         ['conv2d_16[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_16 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_16[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 256, 256, 16  2320        ['activation_16[0][0]']          \n                                )                                                                 \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 256, 256, 16  64         ['conv2d_17[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n activation_17 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_17[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 256, 256, 1)  17          ['activation_17[0][0]']          \n                                                                                                  \n activation_18 (Activation)     (None, 256, 256, 1)  0           ['conv2d_18[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 1,229,953\nTrainable params: 1,227,521\nNon-trainable params: 2,432\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport tensorflow.keras.backend as K\n\nfrom sklearn.metrics import jaccard_score,confusion_matrix\n\ndef IoU_coef(y_true, y_pred):\n    \n    print(y_true.shape)\n    print(y_pred.shape)\n    \n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\ndef dice_coef(y_true, y_pred):\n    \n    print(y_true.shape)\n    print(y_pred.shape)\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:48.501713Z","iopub.execute_input":"2023-08-21T17:36:48.502060Z","iopub.status.idle":"2023-08-21T17:36:48.517777Z","shell.execute_reply.started":"2023-08-21T17:36:48.502026Z","shell.execute_reply":"2023-08-21T17:36:48.517055Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow.keras.backend as K\nimport numpy as np\nimport tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:48.518866Z","iopub.execute_input":"2023-08-21T17:36:48.519777Z","iopub.status.idle":"2023-08-21T17:36:48.526755Z","shell.execute_reply.started":"2023-08-21T17:36:48.519740Z","shell.execute_reply":"2023-08-21T17:36:48.526046Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross Entropy\n# Focal \n# Dice \n# Tversky\n# Tversky Focal\n# Combo\n# Unified Focal (Sym)\n# Unified Focal (Asym)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:48.527881Z","iopub.execute_input":"2023-08-21T17:36:48.528221Z","iopub.status.idle":"2023-08-21T17:36:48.538026Z","shell.execute_reply.started":"2023-08-21T17:36:48.528191Z","shell.execute_reply":"2023-08-21T17:36:48.537338Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dice_loss = DiceLoss()\n# binary_focal_loss = BinaryFocalLoss()\n# combo_loss = binary_crossentropy + dice_loss\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:48.538889Z","iopub.execute_input":"2023-08-21T17:36:48.539228Z","iopub.status.idle":"2023-08-21T17:36:48.544570Z","shell.execute_reply.started":"2023-08-21T17:36:48.539199Z","shell.execute_reply":"2023-08-21T17:36:48.543872Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\ndef dice_coef(y_true, y_pred, smooth=100):        \n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return dice\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:48.545463Z","iopub.execute_input":"2023-08-21T17:36:48.545794Z","iopub.status.idle":"2023-08-21T17:36:48.557862Z","shell.execute_reply.started":"2023-08-21T17:36:48.545764Z","shell.execute_reply":"2023-08-21T17:36:48.557104Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def sym_unified_focal_loss(y_true, y_pred ):\n    \n    axis = identify_axis(y_true.get_shape())\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    \n    def loss_function(y_true,y_pred):\n        weight=0.5\n        delta=0.6 \n        gamma=0.5\n        symmetric_ftl = symmetric_focal_tversky_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n        symmetric_fl = symmetric_focal_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n        if weight is not None:\n            return (weight * symmetric_ftl) + ((1-weight) * symmetric_fl)\n        else:\n            return symmetric_ftl + symmetric_fl\n\n    return loss_function(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:48.558981Z","iopub.execute_input":"2023-08-21T17:36:48.564121Z","iopub.status.idle":"2023-08-21T17:36:48.576096Z","shell.execute_reply.started":"2023-08-21T17:36:48.564079Z","shell.execute_reply":"2023-08-21T17:36:48.575413Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def iou(y_true, y_pred) :\n    \n    def f (y_true, y_pred) :\n        \n        y_true_f = K.flatten(y_true)\n        y_pred_f = K.flatten(y_pred)\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        \n        x = (intersection + 1e-15) / (union + 1e-15)\n        x = x.astype(np.float32)\n        return x\n    \n    return tf.numpy_function(f, [y_true , y_pred] , tf.float32)\n        \n      ","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:48.577336Z","iopub.execute_input":"2023-08-21T17:36:48.577642Z","iopub.status.idle":"2023-08-21T17:36:48.589058Z","shell.execute_reply.started":"2023-08-21T17:36:48.577611Z","shell.execute_reply":"2023-08-21T17:36:48.588174Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-24T13:45:13.680272Z","iopub.execute_input":"2023-06-24T13:45:13.680685Z","iopub.status.idle":"2023-06-24T13:45:13.701549Z","shell.execute_reply.started":"2023-06-24T13:45:13.680635Z","shell.execute_reply":"2023-06-24T13:45:13.700808Z"}}},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-24T18:26:06.269823Z","iopub.execute_input":"2023-06-24T18:26:06.270640Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint , ReduceLROnPlateau , CSVLogger, TensorBoard\nfrom tensorflow.keras.metrics import Recall , Precision\nfrom keras import optimizers\nfrom tensorflow.keras.losses import BinaryFocalCrossentropy\n  \n        \nif __name__ == \"__main__\":\n    \n    \n    np.random.seed(42)\n    tf.random.set_seed(42)\n    batch = 16\n    lr = 1e-1\n    epochs = 100\n    \n    train_dataset= tf_dataset(train_x , train_y, batch = batch)\n    valid_dataset= tf_dataset(valid_x , valid_y, batch = batch)\n    \n    \n    model = build_model()\n    \n    binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\n    opt = tf.keras.optimizers.Adam(lr)\n    \n    metrics = [\"acc\" , Recall() , Precision() , iou , dice_coef]\n    \n    \n    model.compile(loss = dice_coef_loss , optimizer = opt , metrics = metrics)\n    \n    callbacks  = [\n        ModelCheckpoint(\"/kaggle/working/model.h5\"),\n        ReduceLROnPlateau(monitor = \"val_loss\" , factor = 0.8 , patience = 5),\n        EarlyStopping(monitor = \"val_loss\" , patience = 30 , restore_best_weights = False)\n    ]\n    \n    \n    train_steps = len(train_x) // batch\n    valid_steps = len(valid_x) // batch\n    \n    if len(train_x) % batch != 0 :\n        train_steps+= 1\n        \n    if len(valid_x) % batch != 0 :\n        valid_steps+= 1\n\n\n    model.fit(\n        \n        train_dataset, \n        validation_data = valid_dataset,\n        epochs = epochs,\n        steps_per_epoch = train_steps,\n        validation_steps = valid_steps,\n        callbacks = callbacks,\n        shuffle = False\n    )","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:36:48.590464Z","iopub.execute_input":"2023-08-21T17:36:48.590783Z","iopub.status.idle":"2023-08-21T17:47:53.274201Z","shell.execute_reply.started":"2023-08-21T17:36:48.590754Z","shell.execute_reply":"2023-08-21T17:47:53.273230Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/100\n31/31 [==============================] - 40s 590ms/step - loss: 0.7030 - acc: 0.7288 - recall: 0.6276 - precision: 0.2046 - iou: 0.1774 - dice_coef: 0.2975 - val_loss: 0.8438 - val_acc: 0.0826 - val_recall: 1.0000 - val_precision: 0.0876 - val_iou: 0.0847 - val_dice_coef: 0.1560 - lr: 0.1000\nEpoch 2/100\n31/31 [==============================] - 7s 219ms/step - loss: 0.6105 - acc: 0.8268 - recall: 0.5726 - precision: 0.2957 - iou: 0.2452 - dice_coef: 0.3902 - val_loss: 0.8438 - val_acc: 0.0826 - val_recall: 1.0000 - val_precision: 0.0876 - val_iou: 0.0847 - val_dice_coef: 0.1560 - lr: 0.1000\nEpoch 3/100\n31/31 [==============================] - 6s 200ms/step - loss: 0.5804 - acc: 0.8639 - recall: 0.5167 - precision: 0.3584 - iou: 0.2689 - dice_coef: 0.4203 - val_loss: 0.8438 - val_acc: 0.0826 - val_recall: 1.0000 - val_precision: 0.0876 - val_iou: 0.0847 - val_dice_coef: 0.1560 - lr: 0.1000\nEpoch 4/100\n31/31 [==============================] - 7s 224ms/step - loss: 0.5356 - acc: 0.8975 - recall: 0.4693 - precision: 0.4716 - iou: 0.3063 - dice_coef: 0.4648 - val_loss: 0.8435 - val_acc: 0.0849 - val_recall: 1.0000 - val_precision: 0.0878 - val_iou: 0.0849 - val_dice_coef: 0.1563 - lr: 0.1000\nEpoch 5/100\n31/31 [==============================] - 6s 210ms/step - loss: 0.5001 - acc: 0.9013 - recall: 0.5127 - precision: 0.4914 - iou: 0.3354 - dice_coef: 0.5000 - val_loss: 0.8365 - val_acc: 0.1314 - val_recall: 1.0000 - val_precision: 0.0921 - val_iou: 0.0890 - val_dice_coef: 0.1633 - lr: 0.1000\nEpoch 6/100\n31/31 [==============================] - 6s 207ms/step - loss: 0.4935 - acc: 0.9071 - recall: 0.4917 - precision: 0.5222 - iou: 0.3427 - dice_coef: 0.5067 - val_loss: 0.8409 - val_acc: 0.1021 - val_recall: 1.0000 - val_precision: 0.0894 - val_iou: 0.0864 - val_dice_coef: 0.1589 - lr: 0.1000\nEpoch 7/100\n31/31 [==============================] - 6s 203ms/step - loss: 0.4498 - acc: 0.9154 - recall: 0.5351 - precision: 0.5686 - iou: 0.3824 - dice_coef: 0.5497 - val_loss: 0.8362 - val_acc: 0.1327 - val_recall: 1.0000 - val_precision: 0.0922 - val_iou: 0.0892 - val_dice_coef: 0.1636 - lr: 0.1000\nEpoch 8/100\n31/31 [==============================] - 6s 204ms/step - loss: 0.4551 - acc: 0.9110 - recall: 0.5444 - precision: 0.5420 - iou: 0.3776 - dice_coef: 0.5449 - val_loss: 0.8380 - val_acc: 0.1216 - val_recall: 1.0000 - val_precision: 0.0912 - val_iou: 0.0881 - val_dice_coef: 0.1618 - lr: 0.1000\nEpoch 9/100\n31/31 [==============================] - 6s 207ms/step - loss: 0.4253 - acc: 0.9208 - recall: 0.5446 - precision: 0.6028 - iou: 0.4053 - dice_coef: 0.5745 - val_loss: 0.7992 - val_acc: 0.3288 - val_recall: 0.9836 - val_precision: 0.1146 - val_iou: 0.1117 - val_dice_coef: 0.2006 - lr: 0.1000\nEpoch 10/100\n31/31 [==============================] - 6s 204ms/step - loss: 0.4260 - acc: 0.9187 - recall: 0.5595 - precision: 0.5863 - iou: 0.4054 - dice_coef: 0.5741 - val_loss: 0.7856 - val_acc: 0.3841 - val_recall: 0.9832 - val_precision: 0.1238 - val_iou: 0.1201 - val_dice_coef: 0.2139 - lr: 0.1000\nEpoch 11/100\n31/31 [==============================] - 7s 223ms/step - loss: 0.4171 - acc: 0.9202 - recall: 0.5694 - precision: 0.5941 - iou: 0.4145 - dice_coef: 0.5830 - val_loss: 0.6288 - val_acc: 0.7579 - val_recall: 0.8195 - val_precision: 0.2431 - val_iou: 0.2303 - val_dice_coef: 0.3734 - lr: 0.1000\nEpoch 12/100\n31/31 [==============================] - 6s 203ms/step - loss: 0.4014 - acc: 0.9252 - recall: 0.5634 - precision: 0.6301 - iou: 0.4296 - dice_coef: 0.5986 - val_loss: 0.5947 - val_acc: 0.7732 - val_recall: 0.8926 - val_precision: 0.2675 - val_iou: 0.2541 - val_dice_coef: 0.4043 - lr: 0.1000\nEpoch 13/100\n31/31 [==============================] - 5s 179ms/step - loss: 0.3750 - acc: 0.9295 - recall: 0.5914 - precision: 0.6539 - iou: 0.4575 - dice_coef: 0.6247 - val_loss: 0.5477 - val_acc: 0.8146 - val_recall: 0.8621 - val_precision: 0.3075 - val_iou: 0.2938 - val_dice_coef: 0.4508 - lr: 0.1000\nEpoch 14/100\n31/31 [==============================] - 7s 230ms/step - loss: 0.3691 - acc: 0.9313 - recall: 0.5948 - precision: 0.6667 - iou: 0.4636 - dice_coef: 0.6309 - val_loss: 0.5180 - val_acc: 0.8434 - val_recall: 0.8399 - val_precision: 0.3453 - val_iou: 0.3179 - val_dice_coef: 0.4817 - lr: 0.1000\nEpoch 15/100\n31/31 [==============================] - 7s 235ms/step - loss: 0.3543 - acc: 0.9343 - recall: 0.6043 - precision: 0.6867 - iou: 0.4798 - dice_coef: 0.6457 - val_loss: 0.6273 - val_acc: 0.7384 - val_recall: 0.8980 - val_precision: 0.2401 - val_iou: 0.2297 - val_dice_coef: 0.3714 - lr: 0.1000\nEpoch 16/100\n31/31 [==============================] - 6s 189ms/step - loss: 0.3654 - acc: 0.9310 - recall: 0.5971 - precision: 0.6634 - iou: 0.4672 - dice_coef: 0.6347 - val_loss: 0.4645 - val_acc: 0.9175 - val_recall: 0.5465 - val_precision: 0.5369 - val_iou: 0.3629 - val_dice_coef: 0.5305 - lr: 0.1000\nEpoch 17/100\n31/31 [==============================] - 7s 220ms/step - loss: 0.3594 - acc: 0.9324 - recall: 0.6067 - precision: 0.6708 - iou: 0.4742 - dice_coef: 0.6411 - val_loss: 0.6370 - val_acc: 0.7769 - val_recall: 0.7336 - val_precision: 0.2458 - val_iou: 0.2211 - val_dice_coef: 0.3611 - lr: 0.1000\nEpoch 18/100\n31/31 [==============================] - 5s 178ms/step - loss: 0.3409 - acc: 0.9367 - recall: 0.6146 - precision: 0.7021 - iou: 0.4939 - dice_coef: 0.6590 - val_loss: 0.4266 - val_acc: 0.9210 - val_recall: 0.5946 - val_precision: 0.5541 - val_iou: 0.4003 - val_dice_coef: 0.5716 - lr: 0.1000\nEpoch 19/100\n31/31 [==============================] - 7s 227ms/step - loss: 0.3238 - acc: 0.9402 - recall: 0.6249 - precision: 0.7269 - iou: 0.5125 - dice_coef: 0.6757 - val_loss: 0.5975 - val_acc: 0.7606 - val_recall: 0.9292 - val_precision: 0.2618 - val_iou: 0.2531 - val_dice_coef: 0.4029 - lr: 0.1000\nEpoch 20/100\n31/31 [==============================] - 7s 214ms/step - loss: 0.3370 - acc: 0.9371 - recall: 0.6202 - precision: 0.7028 - iou: 0.4980 - dice_coef: 0.6630 - val_loss: 0.4946 - val_acc: 0.8697 - val_recall: 0.7546 - val_precision: 0.3829 - val_iou: 0.3390 - val_dice_coef: 0.5054 - lr: 0.1000\nEpoch 21/100\n31/31 [==============================] - 6s 197ms/step - loss: 0.3197 - acc: 0.9395 - recall: 0.6426 - precision: 0.7124 - iou: 0.5179 - dice_coef: 0.6802 - val_loss: 0.7044 - val_acc: 0.6063 - val_recall: 0.9565 - val_precision: 0.1784 - val_iou: 0.1739 - val_dice_coef: 0.2957 - lr: 0.1000\nEpoch 22/100\n31/31 [==============================] - 6s 201ms/step - loss: 0.3264 - acc: 0.9388 - recall: 0.6299 - precision: 0.7123 - iou: 0.5100 - dice_coef: 0.6738 - val_loss: 0.6738 - val_acc: 0.6716 - val_recall: 0.9253 - val_precision: 0.2030 - val_iou: 0.1953 - val_dice_coef: 0.3263 - lr: 0.1000\nEpoch 23/100\n31/31 [==============================] - 6s 202ms/step - loss: 0.2990 - acc: 0.9439 - recall: 0.6513 - precision: 0.7466 - iou: 0.5426 - dice_coef: 0.7014 - val_loss: 0.4933 - val_acc: 0.8722 - val_recall: 0.7518 - val_precision: 0.3883 - val_iou: 0.3386 - val_dice_coef: 0.5052 - lr: 0.1000\nEpoch 24/100\n31/31 [==============================] - 7s 227ms/step - loss: 0.2835 - acc: 0.9470 - recall: 0.6615 - precision: 0.7683 - iou: 0.5610 - dice_coef: 0.7166 - val_loss: 0.6959 - val_acc: 0.6653 - val_recall: 0.8523 - val_precision: 0.1899 - val_iou: 0.1792 - val_dice_coef: 0.3035 - lr: 0.0800\nEpoch 25/100\n31/31 [==============================] - 6s 213ms/step - loss: 0.2718 - acc: 0.9493 - recall: 0.6700 - precision: 0.7843 - iou: 0.5753 - dice_coef: 0.7288 - val_loss: 0.4999 - val_acc: 0.8524 - val_recall: 0.8485 - val_precision: 0.3613 - val_iou: 0.3342 - val_dice_coef: 0.4997 - lr: 0.0800\nEpoch 26/100\n31/31 [==============================] - 6s 196ms/step - loss: 0.2561 - acc: 0.9519 - recall: 0.6849 - precision: 0.8000 - iou: 0.5957 - dice_coef: 0.7447 - val_loss: 0.5218 - val_acc: 0.8423 - val_recall: 0.8339 - val_precision: 0.3419 - val_iou: 0.3147 - val_dice_coef: 0.4776 - lr: 0.0800\nEpoch 27/100\n31/31 [==============================] - 6s 211ms/step - loss: 0.2443 - acc: 0.9540 - recall: 0.6948 - precision: 0.8131 - iou: 0.6101 - dice_coef: 0.7563 - val_loss: 0.3457 - val_acc: 0.9299 - val_recall: 0.7468 - val_precision: 0.5868 - val_iou: 0.4878 - val_dice_coef: 0.6546 - lr: 0.0800\nEpoch 28/100\n31/31 [==============================] - 6s 200ms/step - loss: 0.2428 - acc: 0.9541 - recall: 0.6967 - precision: 0.8137 - iou: 0.6118 - dice_coef: 0.7578 - val_loss: 0.3231 - val_acc: 0.9350 - val_recall: 0.7626 - val_precision: 0.6142 - val_iou: 0.5105 - val_dice_coef: 0.6752 - lr: 0.0800\nEpoch 29/100\n31/31 [==============================] - 7s 224ms/step - loss: 0.2405 - acc: 0.9545 - recall: 0.7017 - precision: 0.8143 - iou: 0.6149 - dice_coef: 0.7598 - val_loss: 0.3582 - val_acc: 0.9400 - val_recall: 0.5946 - val_precision: 0.6912 - val_iou: 0.4781 - val_dice_coef: 0.6455 - lr: 0.0800\nEpoch 30/100\n31/31 [==============================] - 6s 193ms/step - loss: 0.2453 - acc: 0.9532 - recall: 0.7068 - precision: 0.7984 - iou: 0.6092 - dice_coef: 0.7552 - val_loss: 0.2733 - val_acc: 0.9450 - val_recall: 0.8058 - val_precision: 0.6639 - val_iou: 0.5728 - val_dice_coef: 0.7282 - lr: 0.0800\nEpoch 31/100\n31/31 [==============================] - 6s 203ms/step - loss: 0.2293 - acc: 0.9561 - recall: 0.7228 - precision: 0.8145 - iou: 0.6296 - dice_coef: 0.7713 - val_loss: 0.3180 - val_acc: 0.9296 - val_recall: 0.8459 - val_precision: 0.5766 - val_iou: 0.5194 - val_dice_coef: 0.6828 - lr: 0.0800\nEpoch 32/100\n31/31 [==============================] - 7s 219ms/step - loss: 0.2041 - acc: 0.9608 - recall: 0.7384 - precision: 0.8491 - iou: 0.6634 - dice_coef: 0.7963 - val_loss: 0.3028 - val_acc: 0.9361 - val_recall: 0.8155 - val_precision: 0.6121 - val_iou: 0.5349 - val_dice_coef: 0.6971 - lr: 0.0800\nEpoch 33/100\n31/31 [==============================] - 6s 185ms/step - loss: 0.1974 - acc: 0.9617 - recall: 0.7431 - precision: 0.8552 - iou: 0.6724 - dice_coef: 0.8028 - val_loss: 0.2540 - val_acc: 0.9480 - val_recall: 0.8259 - val_precision: 0.6773 - val_iou: 0.5957 - val_dice_coef: 0.7465 - lr: 0.0800\nEpoch 34/100\n31/31 [==============================] - 7s 239ms/step - loss: 0.1922 - acc: 0.9627 - recall: 0.7473 - precision: 0.8619 - iou: 0.6797 - dice_coef: 0.8081 - val_loss: 0.2757 - val_acc: 0.9462 - val_recall: 0.7699 - val_precision: 0.6806 - val_iou: 0.5670 - val_dice_coef: 0.7237 - lr: 0.0800\nEpoch 35/100\n31/31 [==============================] - 7s 221ms/step - loss: 0.1902 - acc: 0.9631 - recall: 0.7468 - precision: 0.8668 - iou: 0.6822 - dice_coef: 0.8099 - val_loss: 0.2345 - val_acc: 0.9600 - val_recall: 0.7060 - val_precision: 0.8273 - val_iou: 0.6233 - val_dice_coef: 0.7674 - lr: 0.0800\nEpoch 36/100\n31/31 [==============================] - 5s 180ms/step - loss: 0.1781 - acc: 0.9653 - recall: 0.7620 - precision: 0.8769 - iou: 0.7001 - dice_coef: 0.8224 - val_loss: 0.2550 - val_acc: 0.9491 - val_recall: 0.8156 - val_precision: 0.6870 - val_iou: 0.5975 - val_dice_coef: 0.7475 - lr: 0.0800\nEpoch 37/100\n31/31 [==============================] - 6s 200ms/step - loss: 0.1680 - acc: 0.9667 - recall: 0.7733 - precision: 0.8825 - iou: 0.7146 - dice_coef: 0.8326 - val_loss: 0.2457 - val_acc: 0.9610 - val_recall: 0.6382 - val_precision: 0.8984 - val_iou: 0.6086 - val_dice_coef: 0.7563 - lr: 0.0800\nEpoch 38/100\n31/31 [==============================] - 6s 201ms/step - loss: 0.1701 - acc: 0.9668 - recall: 0.7653 - precision: 0.8898 - iou: 0.7112 - dice_coef: 0.8300 - val_loss: 0.2098 - val_acc: 0.9606 - val_recall: 0.8030 - val_precision: 0.7754 - val_iou: 0.6546 - val_dice_coef: 0.7910 - lr: 0.0800\nEpoch 39/100\n31/31 [==============================] - 7s 230ms/step - loss: 0.1765 - acc: 0.9654 - recall: 0.7679 - precision: 0.8737 - iou: 0.7019 - dice_coef: 0.8239 - val_loss: 0.4193 - val_acc: 0.8858 - val_recall: 0.8916 - val_precision: 0.4337 - val_iou: 0.4093 - val_dice_coef: 0.5807 - lr: 0.0800\nEpoch 40/100\n31/31 [==============================] - 6s 192ms/step - loss: 0.1712 - acc: 0.9663 - recall: 0.7704 - precision: 0.8810 - iou: 0.7096 - dice_coef: 0.8290 - val_loss: 0.3513 - val_acc: 0.9170 - val_recall: 0.8675 - val_precision: 0.5256 - val_iou: 0.4815 - val_dice_coef: 0.6498 - lr: 0.0800\nEpoch 41/100\n31/31 [==============================] - 7s 218ms/step - loss: 0.1570 - acc: 0.9687 - recall: 0.7833 - precision: 0.8957 - iou: 0.7307 - dice_coef: 0.8433 - val_loss: 0.2283 - val_acc: 0.9564 - val_recall: 0.7787 - val_precision: 0.7514 - val_iou: 0.6306 - val_dice_coef: 0.7731 - lr: 0.0800\nEpoch 42/100\n31/31 [==============================] - 6s 202ms/step - loss: 0.1411 - acc: 0.9713 - recall: 0.7994 - precision: 0.9078 - iou: 0.7541 - dice_coef: 0.8591 - val_loss: 0.2778 - val_acc: 0.9395 - val_recall: 0.8661 - val_precision: 0.6209 - val_iou: 0.5661 - val_dice_coef: 0.7229 - lr: 0.0800\nEpoch 43/100\n31/31 [==============================] - 6s 185ms/step - loss: 0.1475 - acc: 0.9702 - recall: 0.7979 - precision: 0.8988 - iou: 0.7447 - dice_coef: 0.8528 - val_loss: 0.2059 - val_acc: 0.9589 - val_recall: 0.8412 - val_precision: 0.7461 - val_iou: 0.6592 - val_dice_coef: 0.7946 - lr: 0.0800\nEpoch 44/100\n31/31 [==============================] - 7s 232ms/step - loss: 0.1391 - acc: 0.9716 - recall: 0.8018 - precision: 0.9089 - iou: 0.7575 - dice_coef: 0.8613 - val_loss: 0.2805 - val_acc: 0.9452 - val_recall: 0.7630 - val_precision: 0.6742 - val_iou: 0.5609 - val_dice_coef: 0.7186 - lr: 0.0800\nEpoch 45/100\n31/31 [==============================] - 6s 199ms/step - loss: 0.1347 - acc: 0.9725 - recall: 0.8068 - precision: 0.9144 - iou: 0.7639 - dice_coef: 0.8655 - val_loss: 0.1877 - val_acc: 0.9634 - val_recall: 0.8221 - val_precision: 0.7897 - val_iou: 0.6853 - val_dice_coef: 0.8129 - lr: 0.0800\nEpoch 46/100\n31/31 [==============================] - 5s 179ms/step - loss: 0.1289 - acc: 0.9734 - recall: 0.8128 - precision: 0.9193 - iou: 0.7730 - dice_coef: 0.8712 - val_loss: 0.3004 - val_acc: 0.9376 - val_recall: 0.8013 - val_precision: 0.6214 - val_iou: 0.5362 - val_dice_coef: 0.6977 - lr: 0.0800\nEpoch 47/100\n31/31 [==============================] - 6s 196ms/step - loss: 0.1211 - acc: 0.9747 - recall: 0.8234 - precision: 0.9237 - iou: 0.7851 - dice_coef: 0.8790 - val_loss: 0.2145 - val_acc: 0.9597 - val_recall: 0.7793 - val_precision: 0.7813 - val_iou: 0.6485 - val_dice_coef: 0.7863 - lr: 0.0800\nEpoch 48/100\n31/31 [==============================] - 7s 228ms/step - loss: 0.1173 - acc: 0.9754 - recall: 0.8255 - precision: 0.9289 - iou: 0.7911 - dice_coef: 0.8827 - val_loss: 0.2149 - val_acc: 0.9590 - val_recall: 0.7824 - val_precision: 0.7737 - val_iou: 0.6485 - val_dice_coef: 0.7861 - lr: 0.0800\nEpoch 49/100\n31/31 [==============================] - 6s 186ms/step - loss: 0.1138 - acc: 0.9760 - recall: 0.8274 - precision: 0.9331 - iou: 0.7968 - dice_coef: 0.8864 - val_loss: 0.2229 - val_acc: 0.9586 - val_recall: 0.7723 - val_precision: 0.7756 - val_iou: 0.6353 - val_dice_coef: 0.7770 - lr: 0.0800\nEpoch 50/100\n31/31 [==============================] - 7s 226ms/step - loss: 0.1282 - acc: 0.9733 - recall: 0.8180 - precision: 0.9138 - iou: 0.7744 - dice_coef: 0.8721 - val_loss: 0.3569 - val_acc: 0.9178 - val_recall: 0.8291 - val_precision: 0.5274 - val_iou: 0.4733 - val_dice_coef: 0.6424 - lr: 0.0800\nEpoch 51/100\n31/31 [==============================] - 5s 178ms/step - loss: 0.1191 - acc: 0.9750 - recall: 0.8281 - precision: 0.9229 - iou: 0.7886 - dice_coef: 0.8812 - val_loss: 0.2959 - val_acc: 0.9398 - val_recall: 0.7824 - val_precision: 0.6360 - val_iou: 0.5426 - val_dice_coef: 0.7034 - lr: 0.0640\nEpoch 52/100\n31/31 [==============================] - 7s 215ms/step - loss: 0.1055 - acc: 0.9775 - recall: 0.8414 - precision: 0.9377 - iou: 0.8104 - dice_coef: 0.8947 - val_loss: 0.1927 - val_acc: 0.9623 - val_recall: 0.8152 - val_precision: 0.7836 - val_iou: 0.6783 - val_dice_coef: 0.8078 - lr: 0.0640\nEpoch 53/100\n31/31 [==============================] - 6s 201ms/step - loss: 0.0987 - acc: 0.9786 - recall: 0.8460 - precision: 0.9444 - iou: 0.8218 - dice_coef: 0.9015 - val_loss: 0.2023 - val_acc: 0.9605 - val_recall: 0.8039 - val_precision: 0.7730 - val_iou: 0.6656 - val_dice_coef: 0.7984 - lr: 0.0640\nEpoch 54/100\n31/31 [==============================] - 6s 189ms/step - loss: 0.0927 - acc: 0.9796 - recall: 0.8540 - precision: 0.9478 - iou: 0.8313 - dice_coef: 0.9073 - val_loss: 0.1685 - val_acc: 0.9663 - val_recall: 0.8486 - val_precision: 0.8008 - val_iou: 0.7127 - val_dice_coef: 0.8318 - lr: 0.0640\nEpoch 55/100\n31/31 [==============================] - 6s 209ms/step - loss: 0.0911 - acc: 0.9797 - recall: 0.8590 - precision: 0.9450 - iou: 0.8338 - dice_coef: 0.9089 - val_loss: 0.1666 - val_acc: 0.9685 - val_recall: 0.8015 - val_precision: 0.8492 - val_iou: 0.7163 - val_dice_coef: 0.8342 - lr: 0.0640\nEpoch 56/100\n31/31 [==============================] - 6s 197ms/step - loss: 0.0972 - acc: 0.9787 - recall: 0.8505 - precision: 0.9425 - iou: 0.8236 - dice_coef: 0.9028 - val_loss: 0.1787 - val_acc: 0.9651 - val_recall: 0.8298 - val_precision: 0.8008 - val_iou: 0.6980 - val_dice_coef: 0.8218 - lr: 0.0640\nEpoch 57/100\n31/31 [==============================] - 6s 196ms/step - loss: 0.0925 - acc: 0.9796 - recall: 0.8546 - precision: 0.9478 - iou: 0.8317 - dice_coef: 0.9076 - val_loss: 0.2136 - val_acc: 0.9567 - val_recall: 0.8279 - val_precision: 0.7338 - val_iou: 0.6483 - val_dice_coef: 0.7856 - lr: 0.0640\nEpoch 58/100\n31/31 [==============================] - 7s 220ms/step - loss: 0.0892 - acc: 0.9802 - recall: 0.8603 - precision: 0.9484 - iou: 0.8369 - dice_coef: 0.9108 - val_loss: 0.1508 - val_acc: 0.9715 - val_recall: 0.8138 - val_precision: 0.8714 - val_iou: 0.7380 - val_dice_coef: 0.8490 - lr: 0.0640\nEpoch 59/100\n31/31 [==============================] - 6s 197ms/step - loss: 0.0843 - acc: 0.9810 - recall: 0.8660 - precision: 0.9514 - iou: 0.8452 - dice_coef: 0.9157 - val_loss: 0.1458 - val_acc: 0.9727 - val_recall: 0.8181 - val_precision: 0.8802 - val_iou: 0.7471 - val_dice_coef: 0.8552 - lr: 0.0640\nEpoch 60/100\n31/31 [==============================] - 7s 234ms/step - loss: 0.0805 - acc: 0.9816 - recall: 0.8726 - precision: 0.9522 - iou: 0.8516 - dice_coef: 0.9195 - val_loss: 0.1825 - val_acc: 0.9682 - val_recall: 0.7428 - val_precision: 0.8908 - val_iou: 0.6939 - val_dice_coef: 0.8191 - lr: 0.0640\nEpoch 61/100\n31/31 [==============================] - 6s 195ms/step - loss: 0.0769 - acc: 0.9822 - recall: 0.8764 - precision: 0.9556 - iou: 0.8576 - dice_coef: 0.9231 - val_loss: 0.1582 - val_acc: 0.9720 - val_recall: 0.7632 - val_precision: 0.9175 - val_iou: 0.7279 - val_dice_coef: 0.8423 - lr: 0.0640\nEpoch 62/100\n31/31 [==============================] - 6s 201ms/step - loss: 0.0765 - acc: 0.9823 - recall: 0.8764 - precision: 0.9565 - iou: 0.8583 - dice_coef: 0.9235 - val_loss: 0.1646 - val_acc: 0.9709 - val_recall: 0.7537 - val_precision: 0.9146 - val_iou: 0.7201 - val_dice_coef: 0.8363 - lr: 0.0640\nEpoch 63/100\n31/31 [==============================] - 6s 201ms/step - loss: 0.0765 - acc: 0.9824 - recall: 0.8771 - precision: 0.9560 - iou: 0.8582 - dice_coef: 0.9235 - val_loss: 0.1482 - val_acc: 0.9716 - val_recall: 0.8300 - val_precision: 0.8601 - val_iou: 0.7422 - val_dice_coef: 0.8518 - lr: 0.0640\nEpoch 64/100\n31/31 [==============================] - 6s 202ms/step - loss: 0.0724 - acc: 0.9830 - recall: 0.8837 - precision: 0.9569 - iou: 0.8652 - dice_coef: 0.9275 - val_loss: 0.1819 - val_acc: 0.9690 - val_recall: 0.7169 - val_precision: 0.9240 - val_iou: 0.6927 - val_dice_coef: 0.8184 - lr: 0.0640\nEpoch 65/100\n31/31 [==============================] - 8s 251ms/step - loss: 0.0713 - acc: 0.9833 - recall: 0.8843 - precision: 0.9592 - iou: 0.8671 - dice_coef: 0.9286 - val_loss: 0.1661 - val_acc: 0.9692 - val_recall: 0.8048 - val_precision: 0.8552 - val_iou: 0.7170 - val_dice_coef: 0.8350 - lr: 0.0512\nEpoch 66/100\n31/31 [==============================] - 5s 176ms/step - loss: 0.0671 - acc: 0.9841 - recall: 0.8889 - precision: 0.9628 - iou: 0.8744 - dice_coef: 0.9328 - val_loss: 0.1547 - val_acc: 0.9698 - val_recall: 0.8539 - val_precision: 0.8303 - val_iou: 0.7335 - val_dice_coef: 0.8462 - lr: 0.0512\nEpoch 67/100\n31/31 [==============================] - 7s 218ms/step - loss: 0.0637 - acc: 0.9846 - recall: 0.8959 - precision: 0.9620 - iou: 0.8802 - dice_coef: 0.9362 - val_loss: 0.1462 - val_acc: 0.9716 - val_recall: 0.8570 - val_precision: 0.8446 - val_iou: 0.7446 - val_dice_coef: 0.8536 - lr: 0.0512\nEpoch 68/100\n31/31 [==============================] - 6s 190ms/step - loss: 0.0622 - acc: 0.9848 - recall: 0.8959 - precision: 0.9643 - iou: 0.8830 - dice_coef: 0.9378 - val_loss: 0.1675 - val_acc: 0.9696 - val_recall: 0.7884 - val_precision: 0.8725 - val_iou: 0.7149 - val_dice_coef: 0.8337 - lr: 0.0512\nEpoch 69/100\n31/31 [==============================] - 6s 199ms/step - loss: 0.0623 - acc: 0.9849 - recall: 0.8952 - precision: 0.9654 - iou: 0.8828 - dice_coef: 0.9376 - val_loss: 0.1444 - val_acc: 0.9720 - val_recall: 0.8429 - val_precision: 0.8570 - val_iou: 0.7481 - val_dice_coef: 0.8557 - lr: 0.0512\nEpoch 70/100\n31/31 [==============================] - 7s 230ms/step - loss: 0.0617 - acc: 0.9850 - recall: 0.8977 - precision: 0.9646 - iou: 0.8837 - dice_coef: 0.9382 - val_loss: 0.1606 - val_acc: 0.9689 - val_recall: 0.8405 - val_precision: 0.8300 - val_iou: 0.7242 - val_dice_coef: 0.8399 - lr: 0.0512\nEpoch 71/100\n31/31 [==============================] - 7s 216ms/step - loss: 0.0624 - acc: 0.9849 - recall: 0.8953 - precision: 0.9650 - iou: 0.8826 - dice_coef: 0.9375 - val_loss: 0.1553 - val_acc: 0.9694 - val_recall: 0.8553 - val_precision: 0.8263 - val_iou: 0.7331 - val_dice_coef: 0.8457 - lr: 0.0512\nEpoch 72/100\n31/31 [==============================] - 7s 219ms/step - loss: 0.0590 - acc: 0.9855 - recall: 0.9020 - precision: 0.9652 - iou: 0.8886 - dice_coef: 0.9410 - val_loss: 0.1604 - val_acc: 0.9710 - val_recall: 0.7796 - val_precision: 0.8921 - val_iou: 0.7249 - val_dice_coef: 0.8403 - lr: 0.0512\nEpoch 73/100\n31/31 [==============================] - 6s 189ms/step - loss: 0.0603 - acc: 0.9852 - recall: 0.9007 - precision: 0.9635 - iou: 0.8864 - dice_coef: 0.9397 - val_loss: 0.1724 - val_acc: 0.9664 - val_recall: 0.8496 - val_precision: 0.8015 - val_iou: 0.7073 - val_dice_coef: 0.8285 - lr: 0.0512\nEpoch 74/100\n31/31 [==============================] - 6s 200ms/step - loss: 0.0566 - acc: 0.9858 - recall: 0.9047 - precision: 0.9670 - iou: 0.8928 - dice_coef: 0.9433 - val_loss: 0.1577 - val_acc: 0.9693 - val_recall: 0.8438 - val_precision: 0.8302 - val_iou: 0.7288 - val_dice_coef: 0.8430 - lr: 0.0512\nEpoch 75/100\n31/31 [==============================] - 6s 208ms/step - loss: 0.0588 - acc: 0.9855 - recall: 0.8994 - precision: 0.9681 - iou: 0.8888 - dice_coef: 0.9411 - val_loss: 0.1848 - val_acc: 0.9623 - val_recall: 0.8763 - val_precision: 0.7572 - val_iou: 0.6898 - val_dice_coef: 0.8162 - lr: 0.0410\nEpoch 76/100\n31/31 [==============================] - 7s 236ms/step - loss: 0.0594 - acc: 0.9854 - recall: 0.9001 - precision: 0.9665 - iou: 0.8879 - dice_coef: 0.9405 - val_loss: 0.1517 - val_acc: 0.9713 - val_recall: 0.8138 - val_precision: 0.8695 - val_iou: 0.7384 - val_dice_coef: 0.8492 - lr: 0.0410\nEpoch 77/100\n31/31 [==============================] - 6s 201ms/step - loss: 0.0567 - acc: 0.9859 - recall: 0.9050 - precision: 0.9672 - iou: 0.8928 - dice_coef: 0.9433 - val_loss: 0.1905 - val_acc: 0.9625 - val_recall: 0.8447 - val_precision: 0.7714 - val_iou: 0.6794 - val_dice_coef: 0.8091 - lr: 0.0410\nEpoch 78/100\n31/31 [==============================] - 5s 177ms/step - loss: 0.0526 - acc: 0.9867 - recall: 0.9109 - precision: 0.9695 - iou: 0.9003 - dice_coef: 0.9475 - val_loss: 0.1593 - val_acc: 0.9696 - val_recall: 0.8152 - val_precision: 0.8495 - val_iou: 0.7254 - val_dice_coef: 0.8405 - lr: 0.0410\nEpoch 79/100\n31/31 [==============================] - 6s 202ms/step - loss: 0.0503 - acc: 0.9870 - recall: 0.9126 - precision: 0.9719 - iou: 0.9045 - dice_coef: 0.9498 - val_loss: 0.1486 - val_acc: 0.9721 - val_recall: 0.8211 - val_precision: 0.8717 - val_iou: 0.7424 - val_dice_coef: 0.8521 - lr: 0.0410\nEpoch 80/100\n31/31 [==============================] - 7s 226ms/step - loss: 0.0481 - acc: 0.9874 - recall: 0.9172 - precision: 0.9719 - iou: 0.9084 - dice_coef: 0.9520 - val_loss: 0.1441 - val_acc: 0.9736 - val_recall: 0.7998 - val_precision: 0.9039 - val_iou: 0.7490 - val_dice_coef: 0.8564 - lr: 0.0328\nEpoch 81/100\n31/31 [==============================] - 6s 180ms/step - loss: 0.0446 - acc: 0.9880 - recall: 0.9198 - precision: 0.9754 - iou: 0.9146 - dice_coef: 0.9554 - val_loss: 0.1515 - val_acc: 0.9725 - val_recall: 0.7875 - val_precision: 0.9021 - val_iou: 0.7382 - val_dice_coef: 0.8493 - lr: 0.0328\nEpoch 82/100\n31/31 [==============================] - 7s 218ms/step - loss: 0.0424 - acc: 0.9884 - recall: 0.9226 - precision: 0.9774 - iou: 0.9188 - dice_coef: 0.9576 - val_loss: 0.1668 - val_acc: 0.9706 - val_recall: 0.7547 - val_precision: 0.9096 - val_iou: 0.7159 - val_dice_coef: 0.8340 - lr: 0.0328\nEpoch 83/100\n31/31 [==============================] - 6s 200ms/step - loss: 0.0411 - acc: 0.9886 - recall: 0.9240 - precision: 0.9783 - iou: 0.9211 - dice_coef: 0.9589 - val_loss: 0.1559 - val_acc: 0.9715 - val_recall: 0.7910 - val_precision: 0.8878 - val_iou: 0.7306 - val_dice_coef: 0.8443 - lr: 0.0328\nEpoch 84/100\n31/31 [==============================] - 7s 222ms/step - loss: 0.0398 - acc: 0.9889 - recall: 0.9267 - precision: 0.9786 - iou: 0.9236 - dice_coef: 0.9603 - val_loss: 0.1503 - val_acc: 0.9716 - val_recall: 0.8192 - val_precision: 0.8681 - val_iou: 0.7392 - val_dice_coef: 0.8499 - lr: 0.0328\nEpoch 85/100\n31/31 [==============================] - 6s 189ms/step - loss: 0.0388 - acc: 0.9891 - recall: 0.9261 - precision: 0.9806 - iou: 0.9254 - dice_coef: 0.9612 - val_loss: 0.1388 - val_acc: 0.9739 - val_recall: 0.8194 - val_precision: 0.8920 - val_iou: 0.7564 - val_dice_coef: 0.8613 - lr: 0.0328\nEpoch 86/100\n31/31 [==============================] - 7s 218ms/step - loss: 0.0389 - acc: 0.9890 - recall: 0.9261 - precision: 0.9802 - iou: 0.9253 - dice_coef: 0.9612 - val_loss: 0.1371 - val_acc: 0.9736 - val_recall: 0.8449 - val_precision: 0.8711 - val_iou: 0.7587 - val_dice_coef: 0.8628 - lr: 0.0328\nEpoch 87/100\n31/31 [==============================] - 6s 197ms/step - loss: 0.0391 - acc: 0.9890 - recall: 0.9272 - precision: 0.9790 - iou: 0.9249 - dice_coef: 0.9610 - val_loss: 0.1363 - val_acc: 0.9742 - val_recall: 0.8297 - val_precision: 0.8882 - val_iou: 0.7602 - val_dice_coef: 0.8637 - lr: 0.0328\nEpoch 88/100\n31/31 [==============================] - 6s 205ms/step - loss: 0.0389 - acc: 0.9890 - recall: 0.9287 - precision: 0.9783 - iou: 0.9251 - dice_coef: 0.9611 - val_loss: 0.1362 - val_acc: 0.9740 - val_recall: 0.8317 - val_precision: 0.8853 - val_iou: 0.7608 - val_dice_coef: 0.8641 - lr: 0.0328\nEpoch 89/100\n31/31 [==============================] - 5s 179ms/step - loss: 0.0388 - acc: 0.9891 - recall: 0.9265 - precision: 0.9802 - iou: 0.9253 - dice_coef: 0.9612 - val_loss: 0.1394 - val_acc: 0.9732 - val_recall: 0.8416 - val_precision: 0.8699 - val_iou: 0.7554 - val_dice_coef: 0.8606 - lr: 0.0328\nEpoch 90/100\n31/31 [==============================] - 7s 215ms/step - loss: 0.0392 - acc: 0.9890 - recall: 0.9276 - precision: 0.9791 - iou: 0.9247 - dice_coef: 0.9608 - val_loss: 0.1458 - val_acc: 0.9711 - val_recall: 0.8689 - val_precision: 0.8324 - val_iou: 0.7448 - val_dice_coef: 0.8537 - lr: 0.0328\nEpoch 91/100\n31/31 [==============================] - 6s 203ms/step - loss: 0.0387 - acc: 0.9891 - recall: 0.9292 - precision: 0.9783 - iou: 0.9254 - dice_coef: 0.9612 - val_loss: 0.1417 - val_acc: 0.9724 - val_recall: 0.8492 - val_precision: 0.8563 - val_iou: 0.7516 - val_dice_coef: 0.8581 - lr: 0.0328\nEpoch 92/100\n31/31 [==============================] - 6s 200ms/step - loss: 0.0379 - acc: 0.9892 - recall: 0.9279 - precision: 0.9806 - iou: 0.9269 - dice_coef: 0.9621 - val_loss: 0.1669 - val_acc: 0.9663 - val_recall: 0.8655 - val_precision: 0.7939 - val_iou: 0.7157 - val_dice_coef: 0.8337 - lr: 0.0328\nEpoch 93/100\n31/31 [==============================] - 8s 265ms/step - loss: 0.0377 - acc: 0.9893 - recall: 0.9277 - precision: 0.9813 - iou: 0.9274 - dice_coef: 0.9623 - val_loss: 0.1630 - val_acc: 0.9670 - val_recall: 0.8739 - val_precision: 0.7958 - val_iou: 0.7204 - val_dice_coef: 0.8371 - lr: 0.0262\nEpoch 94/100\n31/31 [==============================] - 7s 219ms/step - loss: 0.0383 - acc: 0.9892 - recall: 0.9294 - precision: 0.9790 - iou: 0.9261 - dice_coef: 0.9616 - val_loss: 0.1436 - val_acc: 0.9717 - val_recall: 0.8669 - val_precision: 0.8395 - val_iou: 0.7476 - val_dice_coef: 0.8555 - lr: 0.0262\nEpoch 95/100\n31/31 [==============================] - 6s 206ms/step - loss: 0.0378 - acc: 0.9893 - recall: 0.9289 - precision: 0.9803 - iou: 0.9272 - dice_coef: 0.9622 - val_loss: 0.1454 - val_acc: 0.9720 - val_recall: 0.8443 - val_precision: 0.8558 - val_iou: 0.7459 - val_dice_coef: 0.8544 - lr: 0.0262\nEpoch 96/100\n31/31 [==============================] - 6s 186ms/step - loss: 0.0354 - acc: 0.9897 - recall: 0.9320 - precision: 0.9816 - iou: 0.9317 - dice_coef: 0.9646 - val_loss: 0.1522 - val_acc: 0.9709 - val_recall: 0.8333 - val_precision: 0.8531 - val_iou: 0.7361 - val_dice_coef: 0.8479 - lr: 0.0262\nEpoch 97/100\n31/31 [==============================] - 6s 194ms/step - loss: 0.0342 - acc: 0.9899 - recall: 0.9322 - precision: 0.9834 - iou: 0.9338 - dice_coef: 0.9658 - val_loss: 0.1431 - val_acc: 0.9726 - val_recall: 0.8351 - val_precision: 0.8689 - val_iou: 0.7500 - val_dice_coef: 0.8570 - lr: 0.0262\nEpoch 98/100\n31/31 [==============================] - 6s 199ms/step - loss: 0.0350 - acc: 0.9898 - recall: 0.9328 - precision: 0.9818 - iou: 0.9324 - dice_coef: 0.9650 - val_loss: 0.1418 - val_acc: 0.9726 - val_recall: 0.8409 - val_precision: 0.8645 - val_iou: 0.7514 - val_dice_coef: 0.8579 - lr: 0.0210\nEpoch 99/100\n31/31 [==============================] - 7s 221ms/step - loss: 0.0343 - acc: 0.9899 - recall: 0.9346 - precision: 0.9816 - iou: 0.9338 - dice_coef: 0.9658 - val_loss: 0.1336 - val_acc: 0.9745 - val_recall: 0.8326 - val_precision: 0.8889 - val_iou: 0.7649 - val_dice_coef: 0.8667 - lr: 0.0210\nEpoch 100/100\n31/31 [==============================] - 6s 201ms/step - loss: 0.0334 - acc: 0.9900 - recall: 0.9356 - precision: 0.9822 - iou: 0.9354 - dice_coef: 0.9666 - val_loss: 0.1352 - val_acc: 0.9740 - val_recall: 0.8432 - val_precision: 0.8759 - val_iou: 0.7620 - val_dice_coef: 0.8649 - lr: 0.0210\n","output_type":"stream"}]},{"cell_type":"code","source":"def read_image_new(path):\n    \n    x = cv2.imread(path , cv2.IMREAD_COLOR)\n    x = cv2.resize(x , (256, 256))\n    x = x/255.0\n    # size is 256, 256 , 3\n    return x\n\n\ndef read_mask_new(path):\n\n    x = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x , (256, 256))\n    # size is 256, 256\n    x = np.expand_dims(x, axis = -1)\n    # size is 256, 256 , 1\n    \n    return x\n\ndef mask_parse(mask):\n    \n    mask = np.squeeze(mask)\n    mask = [mask , mask , mask]\n    \n    mask = np.transpose(mask , (1,2,0))\n    return mask","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:47:53.277371Z","iopub.execute_input":"2023-08-21T17:47:53.277661Z","iopub.status.idle":"2023-08-21T17:47:53.287104Z","shell.execute_reply.started":"2023-08-21T17:47:53.277636Z","shell.execute_reply":"2023-08-21T17:47:53.286124Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom tensorflow.keras.utils import CustomObjectScope\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:47:53.290394Z","iopub.execute_input":"2023-08-21T17:47:53.290651Z","iopub.status.idle":"2023-08-21T17:47:53.300832Z","shell.execute_reply.started":"2023-08-21T17:47:53.290629Z","shell.execute_reply":"2023-08-21T17:47:53.299950Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    test_dataset = tf_dataset(test_x , test_y , batch = batch)\n    test_steps = len(test_x) // batch\n    \n    if len(test_x)%batch != 0 :\n        test_steps +=1\n        \n    with CustomObjectScope({'iou' : iou , 'symmetric_focal_loss': symmetric_focal_loss, 'dice_coef' : dice_coef ,  'dice_coef_loss' :dice_coef_loss , 'tversky_loss':tversky_loss }):\n    \n\n\n        model = tf.keras.models.load_model(\"/kaggle/working/model.h5\")\n        \n    model.evaluate(test_dataset , steps = test_steps)\n    \n    for i , (x,y) in tqdm(enumerate(zip(test_x , test_y)) , total= len(test_x)):\n        \n        x = read_image_new(x)\n        y = read_mask_new(y)\n        \n        y_pred = model.predict(np.expand_dims(x , axis = 0))\n        \n        y_pred= y_pred[0] > 0.5\n        \n        h,w, _ = x.shape\n        \n        white_line = np.ones((h,10,3)) * 255.0\n        \n        all_images = [\n            \n            x*255.0, white_line,\n            \n            mask_parse(y) , white_line,\n            mask_parse(y_pred)*255.0\n            \n        ]\n        \n        image = np.concatenate (all_images, axis =1)\n        cv2.imwrite(f\"/kaggle/working/{i}.png\" , image)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:47:53.302284Z","iopub.execute_input":"2023-08-21T17:47:53.302694Z","iopub.status.idle":"2023-08-21T17:47:53.963991Z","shell.execute_reply.started":"2023-08-21T17:47:53.302640Z","shell.execute_reply":"2023-08-21T17:47:53.962761Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_x)\u001b[38;5;241m%\u001b[39mbatch \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m      7\u001b[0m     test_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m CustomObjectScope({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miou\u001b[39m\u001b[38;5;124m'\u001b[39m : iou , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymmetric_focal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43msymmetric_focal_loss\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdice_coef\u001b[39m\u001b[38;5;124m'\u001b[39m : dice_coef ,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdice_coef_loss\u001b[39m\u001b[38;5;124m'\u001b[39m :dice_coef_loss , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtversky_loss\u001b[39m\u001b[38;5;124m'\u001b[39m:tversky_loss }):\n\u001b[1;32m     13\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_dataset , steps \u001b[38;5;241m=\u001b[39m test_steps)\n","\u001b[0;31mNameError\u001b[0m: name 'symmetric_focal_loss' is not defined"],"ename":"NameError","evalue":"name 'symmetric_focal_loss' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r cvc_newnewnew.zip   \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:47:53.965113Z","iopub.status.idle":"2023-08-21T17:47:53.966152Z","shell.execute_reply.started":"2023-08-21T17:47:53.965881Z","shell.execute_reply":"2023-08-21T17:47:53.965906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:47:53.967299Z","iopub.status.idle":"2023-08-21T17:47:53.968009Z","shell.execute_reply.started":"2023-08-21T17:47:53.967775Z","shell.execute_reply":"2023-08-21T17:47:53.967797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !zip -r segmentation_model.zip  \"/kaggle/input/segmentation-model\"","metadata":{"execution":{"iopub.status.busy":"2023-08-21T17:47:53.969365Z","iopub.status.idle":"2023-08-21T17:47:53.970172Z","shell.execute_reply.started":"2023-08-21T17:47:53.969920Z","shell.execute_reply":"2023-08-21T17:47:53.969942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}